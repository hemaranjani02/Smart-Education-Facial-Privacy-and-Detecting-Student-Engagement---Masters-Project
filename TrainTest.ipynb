{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os.path import join as ospj\n",
    "from os.path import exists as osex\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "      <th>f_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100011003.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100011003</td>\n",
       "      <td>C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100011004.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100011004</td>\n",
       "      <td>C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ClipID  Boredom  Engagement  Confusion  Frustration      f_name  \\\n",
       "0  1100011002.avi        0           2          0            0  1100011002   \n",
       "1  1100011003.avi        0           2          0            0  1100011003   \n",
       "2  1100011004.avi        0           3          0            0  1100011004   \n",
       "\n",
       "                                                path  \n",
       "0  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  \n",
       "1  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  \n",
       "2  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels=pd.read_csv(r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels.csv', index_col=0)\n",
    "df_train_labels[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampler\n",
    "This takes samples from each video (300 frames) and make batches manually  \n",
    "training data: 300 frames * 5482 videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Number of frames checker\n",
    "\n",
    "# for i, label_path in enumerate(df_train_labels.values):\n",
    "#     _df=pd.read_csv(label_path[-1], index_col=0)\n",
    "#     # assert len(_df.index)==300\n",
    "#     if i%100==0:\n",
    "#         print(i, end=' ')\n",
    "#     if len(_df.index)!=300:\n",
    "#         print('length:', len(_df.index))\n",
    "#         print('at: ',label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_DataLoader:\n",
    "    def __init__():\n",
    "        pass\n",
    "    def __get_item__():\n",
    "        pass\n",
    "    def __len__():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1100011002.avi', 0, 2, 0, 0, 1100011002,\n",
       "       'C:\\\\GitHub\\\\Smart-Education-data\\\\data\\\\DAiSEE\\\\Sorted\\\\OpenFace\\\\1100011002.csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(df_train_labels.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put seed here\n",
    "seed=0\n",
    "#select seed mode here\n",
    "SEED_BY_DATA=False\n",
    "SEED_ONCE=True\n",
    "#choose amount of samples\n",
    "n=10\n",
    "batch_size=500\n",
    "assert batch_size%n==0\n",
    "\n",
    "print(df_train_labels.columns)\n",
    "\n",
    "label_iter=iter(df_train_labels.values)\n",
    "\n",
    "np.random.seed(seed)\n",
    "len_data=n*len(df_train_labels.index)\n",
    "print(len_data)\n",
    "\n",
    "# train_loder=Custom_DataLoader()\n",
    "train_loader=[]\n",
    "\n",
    "def build_sample(n, label_iter):\n",
    "    labels=next(label_iter)\n",
    "    df_sample=pd.read_csv(labels[-1], index_col=0).sample(n=n, frac=None, random_state=None) #use global seed\n",
    "    df_sample['Boredom']=labels[1] #add Boredom column\n",
    "    df_sample['Engagement']=labels[2] #add Engagement column\n",
    "    df_sample['Confusion']=labels[3] #add Confusion column\n",
    "    df_sample['Frustration']=labels[4] #add Frustration column\n",
    "    return df_sample\n",
    "\n",
    "for batch in range(len_data//batch_size+1):\n",
    "    idx_start=batch*batch_size\n",
    "    idx_end=(batch+1)*batch_size if (batch+1)*batch_size<len_data else len_data\n",
    "    print(batch, idx_start, idx_end)\n",
    "    idx_curr=idx_start\n",
    "    \n",
    "    #init before while operation\n",
    "    labels=next(label_iter)\n",
    "    # df_sample=pd.read_csv(labels[-1], index_col=0).sample(n=n, frac=None, random_state=None) #use global seed\n",
    "    df_sample=build_sample(n, label_iter)\n",
    "    sample=torch.Tensor(df_sample.values)\n",
    "    # print(sample.shape)\n",
    "    idx_curr+=n\n",
    "    while idx_end-idx_curr>=n:\n",
    "        try: #read n samples\n",
    "            df_sample=build_sample(n, label_iter)\n",
    "            # labels=next(label_iter)\n",
    "            # df_sample=pd.read_csv(labels[-1], index_col=0).sample(n=n, frac=None, random_state=None) #use global seed\n",
    "            # df_sample['Boredom']=labels[1] #add Boredom column\n",
    "            # df_sample['Engagement']=labels[2] #add Engagement column\n",
    "            # df_sample['Confusion']=labels[3] #add Confusion column\n",
    "            # df_sample['Frustration']=labels[4] #add Frustration column\n",
    "            sample=torch.vstack((sample, torch.Tensor(df_sample.values)))\n",
    "            # print(sample.shape)\n",
    "            idx_curr+=n\n",
    "        except:\n",
    "            pass\n",
    "    # print(sample.shape)\n",
    "    train_loader.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 6.9330, 0.9800,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 6.2670, 0.9800,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        [0.0000, 0.4000, 0.9800,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 4.5330, 0.9800,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 7.4670, 0.9800,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6670, 0.9800,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ClipID', 'Boredom', 'Engagement', 'Confusion', 'Frustration ',\n",
      "       'f_name', 'path'],\n",
      "      dtype='object')\n",
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 "
     ]
    }
   ],
   "source": [
    "#put seed here\n",
    "seed=0\n",
    "#select seed mode here\n",
    "SEED_BY_DATA=False\n",
    "SEED_ONCE=True\n",
    "#choose amount of samples\n",
    "n=1\n",
    "frac=None\n",
    "\n",
    "print(df_train_labels.columns)\n",
    "np.random.seed(seed)\n",
    "for i, label_path in enumerate(df_train_labels.values):\n",
    "    _df=pd.read_csv(label_path[-1], index_col=0)\n",
    "    _df['Boredom']=label_path[1] #add Boredom column\n",
    "    _df['Engagement']=label_path[2] #add Engagement column\n",
    "    _df['Confusion']=label_path[3] #add Confusion column\n",
    "    _df['Frustration']=label_path[4] #add Frustration column\n",
    "    if SEED_BY_DATA:\n",
    "        _sample=_df.sample(n, frac, random_state=seed)\n",
    "    elif SEED_ONCE:\n",
    "        _sample=_df.sample(n, frac, random_state=None)\n",
    "    # print(_sample)\n",
    "    if i%100==0:\n",
    "        print(i, end=' ')\n",
    "\n",
    "'''\n",
    "Index(['ClipID', 'Boredom', 'Engagement', 'Confusion', 'Frustration ',\n",
    "       'f_name', 'path'],\n",
    "      dtype='object')\n",
    "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 \n",
    "1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 \n",
    "3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 \n",
    "4600 4700 4800 4900 5000 5100 5200 5300 5400 \n",
    "''' #7m 30.2s\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub\\Smart-Education\\EngaementModel\\TrainTest.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m n\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m frac\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(df_train_labels\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(seed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, label_path \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(df_train_labels\u001b[39m.\u001b[39mvalues):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train_labels' is not defined"
     ]
    }
   ],
   "source": [
    "#put seed here\n",
    "seed=0\n",
    "#select seed mode here\n",
    "SEED_BY_DATA=False\n",
    "SEED_ONCE=True\n",
    "#choose amount of samples\n",
    "n=10\n",
    "frac=None\n",
    "\n",
    "print(df_train_labels.columns)\n",
    "np.random.seed(seed)\n",
    "for i, label_path in enumerate(df_train_labels.values):\n",
    "    _df=pd.read_csv(label_path[-1], index_col=0)\n",
    "    _df['Boredom']=label_path[1] #add Boredom column\n",
    "    _df['Engagement']=label_path[2] #add Engagement column\n",
    "    _df['Confusion']=label_path[3] #add Confusion column\n",
    "    _df['Frustration']=label_path[4] #add Frustration column\n",
    "    if SEED_BY_DATA:\n",
    "        _sample=_df.sample(n, frac, random_state=seed)\n",
    "    elif SEED_ONCE:\n",
    "        _sample=_df.sample(n, frac, random_state=None)\n",
    "    # print(_sample)\n",
    "    if i%100==0:\n",
    "        print(i, end=' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building column names in dataloader..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['frame',\n",
    "                  'face_id',\n",
    "                  'timestamp',\n",
    "                  'confidence',\n",
    "                  'success',\n",
    "                  'gaze_0_x', 'gaze_0_y', 'gaze_0_z',\n",
    "                  'gaze_1_x', 'gaze_1_y', 'gaze_1_z',\n",
    "                  'gaze_angle_x', 'gaze_angle_y', \n",
    "                  'eye_lmk_x_0', 'eye_lmk_x_1', 'eye_lmk_x_2', 'eye_lmk_x_3', 'eye_lmk_x_4',\n",
    "                  'eye_lmk_x_5', 'eye_lmk_x_6', 'eye_lmk_x_7', 'eye_lmk_x_8', 'eye_lmk_x_9',\n",
    "                  'eye_lmk_x_10', 'eye_lmk_x_11', 'eye_lmk_x_12', 'eye_lmk_x_13', 'eye_lmk_x_14',\n",
    "                  'eye_lmk_x_15', 'eye_lmk_x_16', 'eye_lmk_x_17', 'eye_lmk_x_18', 'eye_lmk_x_19',\n",
    "                  'eye_lmk_x_20', 'eye_lmk_x_21', 'eye_lmk_x_22', 'eye_lmk_x_23', 'eye_lmk_x_24',\n",
    "                  'eye_lmk_x_25', 'eye_lmk_x_26', 'eye_lmk_x_27', 'eye_lmk_x_28', 'eye_lmk_x_29',\n",
    "                  'eye_lmk_x_30', 'eye_lmk_x_31', 'eye_lmk_x_32', 'eye_lmk_x_33', 'eye_lmk_x_34',\n",
    "                  'eye_lmk_x_35', 'eye_lmk_x_36', 'eye_lmk_x_37', 'eye_lmk_x_38', 'eye_lmk_x_39',\n",
    "                  'eye_lmk_x_40', 'eye_lmk_x_41', 'eye_lmk_x_42', 'eye_lmk_x_43', 'eye_lmk_x_44',\n",
    "                  'eye_lmk_x_45', 'eye_lmk_x_46', 'eye_lmk_x_47', 'eye_lmk_x_48', 'eye_lmk_x_49',\n",
    "                  'eye_lmk_x_50', 'eye_lmk_x_51', 'eye_lmk_x_52', 'eye_lmk_x_53', 'eye_lmk_x_54',\n",
    "                  'eye_lmk_x_55',\n",
    "                  'eye_lmk_y_0', 'eye_lmk_y_1', 'eye_lmk_y_2', 'eye_lmk_y_3', 'eye_lmk_y_4',\n",
    "                  'eye_lmk_y_5', 'eye_lmk_y_6', 'eye_lmk_y_7', 'eye_lmk_y_8', 'eye_lmk_y_9',\n",
    "                  'eye_lmk_y_10', 'eye_lmk_y_11', 'eye_lmk_y_12', 'eye_lmk_y_13', 'eye_lmk_y_14',\n",
    "                  'eye_lmk_y_15', 'eye_lmk_y_16', 'eye_lmk_y_17', 'eye_lmk_y_18', 'eye_lmk_y_19',\n",
    "                  'eye_lmk_y_20', 'eye_lmk_y_21', 'eye_lmk_y_22', 'eye_lmk_y_23', 'eye_lmk_y_24',\n",
    "                  'eye_lmk_y_25', 'eye_lmk_y_26', 'eye_lmk_y_27', 'eye_lmk_y_28', 'eye_lmk_y_29',\n",
    "                  'eye_lmk_y_30', 'eye_lmk_y_31', 'eye_lmk_y_32', 'eye_lmk_y_33', 'eye_lmk_y_34',\n",
    "                  'eye_lmk_y_35', 'eye_lmk_y_36', 'eye_lmk_y_37', 'eye_lmk_y_38', 'eye_lmk_y_39',\n",
    "                  'eye_lmk_y_40', 'eye_lmk_y_41', 'eye_lmk_y_42', 'eye_lmk_y_43', 'eye_lmk_y_44',\n",
    "                  'eye_lmk_y_45', 'eye_lmk_y_46', 'eye_lmk_y_47', 'eye_lmk_y_48', 'eye_lmk_y_49',\n",
    "                  'eye_lmk_y_50', 'eye_lmk_y_51', 'eye_lmk_y_52', 'eye_lmk_y_53', 'eye_lmk_y_54',\n",
    "                  'eye_lmk_y_55',\n",
    "                  'eye_lmk_X_0', 'eye_lmk_X_1', 'eye_lmk_X_2', 'eye_lmk_X_3', 'eye_lmk_X_4', \n",
    "                  'eye_lmk_X_5', 'eye_lmk_X_6', 'eye_lmk_X_7', 'eye_lmk_X_8', 'eye_lmk_X_9',\n",
    "                  'eye_lmk_X_10', 'eye_lmk_X_11', 'eye_lmk_X_12', 'eye_lmk_X_13', 'eye_lmk_X_14',\n",
    "                  'eye_lmk_X_15', 'eye_lmk_X_16', 'eye_lmk_X_17', 'eye_lmk_X_18', 'eye_lmk_X_19',\n",
    "                  'eye_lmk_X_20', 'eye_lmk_X_21', 'eye_lmk_X_22', 'eye_lmk_X_23', 'eye_lmk_X_24',\n",
    "                  'eye_lmk_X_25', 'eye_lmk_X_26', 'eye_lmk_X_27', 'eye_lmk_X_28', 'eye_lmk_X_29',\n",
    "                  'eye_lmk_X_30', 'eye_lmk_X_31', 'eye_lmk_X_32', 'eye_lmk_X_33', 'eye_lmk_X_34',\n",
    "                  'eye_lmk_X_35', 'eye_lmk_X_36', 'eye_lmk_X_37', 'eye_lmk_X_38', 'eye_lmk_X_39',\n",
    "                  'eye_lmk_X_40', 'eye_lmk_X_41', 'eye_lmk_X_42', 'eye_lmk_X_43', 'eye_lmk_X_44',\n",
    "                  'eye_lmk_X_45', 'eye_lmk_X_46', 'eye_lmk_X_47', 'eye_lmk_X_48', 'eye_lmk_X_49',\n",
    "                  'eye_lmk_X_50', 'eye_lmk_X_51', 'eye_lmk_X_52', 'eye_lmk_X_53', 'eye_lmk_X_54', \n",
    "                  'eye_lmk_X_55', \n",
    "                  'eye_lmk_Y_0', 'eye_lmk_Y_1', 'eye_lmk_Y_2', 'eye_lmk_Y_3', 'eye_lmk_Y_4',\n",
    "                  'eye_lmk_Y_5', 'eye_lmk_Y_6', 'eye_lmk_Y_7', 'eye_lmk_Y_8', 'eye_lmk_Y_9',\n",
    "                  'eye_lmk_Y_10', 'eye_lmk_Y_11', 'eye_lmk_Y_12', 'eye_lmk_Y_13', 'eye_lmk_Y_14',\n",
    "                  'eye_lmk_Y_15', 'eye_lmk_Y_16', 'eye_lmk_Y_17', 'eye_lmk_Y_18', 'eye_lmk_Y_19',\n",
    "                  'eye_lmk_Y_20', 'eye_lmk_Y_21', 'eye_lmk_Y_22', 'eye_lmk_Y_23', 'eye_lmk_Y_24',\n",
    "                  'eye_lmk_Y_25', 'eye_lmk_Y_26', 'eye_lmk_Y_27', 'eye_lmk_Y_28', 'eye_lmk_Y_29',\n",
    "                  'eye_lmk_Y_30', 'eye_lmk_Y_31', 'eye_lmk_Y_32', 'eye_lmk_Y_33', 'eye_lmk_Y_34',\n",
    "                  'eye_lmk_Y_35', 'eye_lmk_Y_36', 'eye_lmk_Y_37', 'eye_lmk_Y_38', 'eye_lmk_Y_39',\n",
    "                  'eye_lmk_Y_40', 'eye_lmk_Y_41', 'eye_lmk_Y_42', 'eye_lmk_Y_43', 'eye_lmk_Y_44',\n",
    "                  'eye_lmk_Y_45', 'eye_lmk_Y_46', 'eye_lmk_Y_47', 'eye_lmk_Y_48', 'eye_lmk_Y_49',\n",
    "                  'eye_lmk_Y_50', 'eye_lmk_Y_51', 'eye_lmk_Y_52', 'eye_lmk_Y_53', 'eye_lmk_Y_54',\n",
    "                  'eye_lmk_Y_55', \n",
    "                  'eye_lmk_Z_0', 'eye_lmk_Z_1', 'eye_lmk_Z_2', 'eye_lmk_Z_3', 'eye_lmk_Z_4',\n",
    "                  'eye_lmk_Z_5', 'eye_lmk_Z_6', 'eye_lmk_Z_7', 'eye_lmk_Z_8', 'eye_lmk_Z_9', \n",
    "                  'eye_lmk_Z_10', 'eye_lmk_Z_11', 'eye_lmk_Z_12', 'eye_lmk_Z_13', 'eye_lmk_Z_14', \n",
    "                  'eye_lmk_Z_15', 'eye_lmk_Z_16', 'eye_lmk_Z_17', 'eye_lmk_Z_18', 'eye_lmk_Z_19',\n",
    "                  'eye_lmk_Z_20', 'eye_lmk_Z_21', 'eye_lmk_Z_22', 'eye_lmk_Z_23', 'eye_lmk_Z_24', \n",
    "                  'eye_lmk_Z_25', 'eye_lmk_Z_26', 'eye_lmk_Z_27', 'eye_lmk_Z_28', 'eye_lmk_Z_29',\n",
    "                  'eye_lmk_Z_30', 'eye_lmk_Z_31', 'eye_lmk_Z_32', 'eye_lmk_Z_33', 'eye_lmk_Z_34', \n",
    "                  'eye_lmk_Z_35', 'eye_lmk_Z_36', 'eye_lmk_Z_37', 'eye_lmk_Z_38', 'eye_lmk_Z_39',\n",
    "                  'eye_lmk_Z_40', 'eye_lmk_Z_41', 'eye_lmk_Z_42', 'eye_lmk_Z_43', 'eye_lmk_Z_44', \n",
    "                  'eye_lmk_Z_45', 'eye_lmk_Z_46', 'eye_lmk_Z_47', 'eye_lmk_Z_48', 'eye_lmk_Z_49', \n",
    "                  'eye_lmk_Z_50', 'eye_lmk_Z_51', 'eye_lmk_Z_52', 'eye_lmk_Z_53', 'eye_lmk_Z_54', \n",
    "                  'eye_lmk_Z_55', \n",
    "                  'pose_Tx', 'pose_Ty', 'pose_Tz', 'pose_Rx', 'pose_Ry', 'pose_Rz',\n",
    "                  'x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', \n",
    "                  'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19',\n",
    "                  'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29',\n",
    "                  'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', \n",
    "                  'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_49',\n",
    "                  'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59',\n",
    "                  'x_60', 'x_61', 'x_62', 'x_63', 'x_64', 'x_65', 'x_66', 'x_67',\n",
    "                  'y_0', 'y_1', 'y_2', 'y_3', 'y_4', 'y_5', 'y_6', 'y_7', 'y_8', 'y_9',\n",
    "                  'y_10', 'y_11', 'y_12', 'y_13', 'y_14', 'y_15', 'y_16', 'y_17', 'y_18', 'y_19', \n",
    "                  'y_20', 'y_21', 'y_22', 'y_23', 'y_24', 'y_25', 'y_26', 'y_27', 'y_28', 'y_29',\n",
    "                  'y_30', 'y_31', 'y_32', 'y_33', 'y_34', 'y_35', 'y_36', 'y_37', 'y_38', 'y_39',\n",
    "                  'y_40', 'y_41', 'y_42', 'y_43', 'y_44', 'y_45', 'y_46', 'y_47', 'y_48', 'y_49', \n",
    "                  'y_50', 'y_51', 'y_52', 'y_53', 'y_54', 'y_55', 'y_56', 'y_57', 'y_58', 'y_59', \n",
    "                  'y_60', 'y_61', 'y_62', 'y_63', 'y_64', 'y_65', 'y_66', 'y_67', \n",
    "                  'X_0', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', \n",
    "                  'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19', \n",
    "                  'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29', \n",
    "                  'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38', 'X_39', \n",
    "                  'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_47', 'X_48', 'X_49', \n",
    "                  'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56', 'X_57', 'X_58', 'X_59', \n",
    "                  'X_60', 'X_61', 'X_62', 'X_63', 'X_64', 'X_65', 'X_66', 'X_67', \n",
    "                  'Y_0', 'Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9',\n",
    "                  'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14', 'Y_15', 'Y_16', 'Y_17', 'Y_18', 'Y_19',\n",
    "                  'Y_20', 'Y_21', 'Y_22', 'Y_23', 'Y_24', 'Y_25', 'Y_26', 'Y_27', 'Y_28', 'Y_29', \n",
    "                  'Y_30', 'Y_31', 'Y_32', 'Y_33', 'Y_34', 'Y_35', 'Y_36', 'Y_37', 'Y_38', 'Y_39', \n",
    "                  'Y_40', 'Y_41', 'Y_42', 'Y_43', 'Y_44', 'Y_45', 'Y_46', 'Y_47', 'Y_48', 'Y_49', \n",
    "                  'Y_50', 'Y_51', 'Y_52', 'Y_53', 'Y_54', 'Y_55', 'Y_56', 'Y_57', 'Y_58', 'Y_59', \n",
    "                  'Y_60', 'Y_61', 'Y_62', 'Y_63', 'Y_64', 'Y_65', 'Y_66', 'Y_67',\n",
    "                  'Z_0', 'Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9',\n",
    "                  'Z_10', 'Z_11', 'Z_12', 'Z_13', 'Z_14', 'Z_15', 'Z_16', 'Z_17', 'Z_18', 'Z_19',\n",
    "                  'Z_20', 'Z_21', 'Z_22', 'Z_23', 'Z_24', 'Z_25', 'Z_26', 'Z_27', 'Z_28', 'Z_29',\n",
    "                  'Z_30', 'Z_31', 'Z_32', 'Z_33', 'Z_34', 'Z_35', 'Z_36', 'Z_37', 'Z_38', 'Z_39',\n",
    "                  'Z_40', 'Z_41', 'Z_42', 'Z_43', 'Z_44', 'Z_45', 'Z_46', 'Z_47', 'Z_48', 'Z_49',\n",
    "                  'Z_50', 'Z_51', 'Z_52', 'Z_53', 'Z_54', 'Z_55', 'Z_56', 'Z_57', 'Z_58', 'Z_59',\n",
    "                  'Z_60', 'Z_61', 'Z_62', 'Z_63', 'Z_64', 'Z_65', 'Z_66', 'Z_67',\n",
    "                  'p_scale', 'p_rx', 'p_ry', 'p_rz', 'p_tx', 'p_ty', \n",
    "                  'p_0', 'p_1', 'p_2', 'p_3', 'p_4', 'p_5', 'p_6', 'p_7', 'p_8', 'p_9', \n",
    "                  'p_10', 'p_11', 'p_12', 'p_13', 'p_14', 'p_15', 'p_16', 'p_17', 'p_18', 'p_19',\n",
    "                  'p_20', 'p_21', 'p_22', 'p_23', 'p_24', 'p_25', 'p_26', 'p_27', 'p_28', 'p_29', \n",
    "                  'p_30', 'p_31', 'p_32', 'p_33', \n",
    "                  'AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', \n",
    "                  'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', \n",
    "                  'AU45_r', \n",
    "                  'AU01_c', 'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c', \n",
    "                  'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c', 'AU26_c', \n",
    "                  'AU28_c', 'AU45_c'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='frame, face_id, timestamp, confidence, success, gaze_0_x, gaze_0_y, gaze_0_z, gaze_1_x, gaze_1_y, gaze_1_z, gaze_angle_x, gaze_angle_y, eye_lmk_x_0, eye_lmk_x_1, eye_lmk_x_2, eye_lmk_x_3, eye_lmk_x_4, eye_lmk_x_5, eye_lmk_x_6, eye_lmk_x_7, eye_lmk_x_8, eye_lmk_x_9, eye_lmk_x_10, eye_lmk_x_11, eye_lmk_x_12, eye_lmk_x_13, eye_lmk_x_14, eye_lmk_x_15, eye_lmk_x_16, eye_lmk_x_17, eye_lmk_x_18, eye_lmk_x_19, eye_lmk_x_20, eye_lmk_x_21, eye_lmk_x_22, eye_lmk_x_23, eye_lmk_x_24, eye_lmk_x_25, eye_lmk_x_26, eye_lmk_x_27, eye_lmk_x_28, eye_lmk_x_29, eye_lmk_x_30, eye_lmk_x_31, eye_lmk_x_32, eye_lmk_x_33, eye_lmk_x_34, eye_lmk_x_35, eye_lmk_x_36, eye_lmk_x_37, eye_lmk_x_38, eye_lmk_x_39, eye_lmk_x_40, eye_lmk_x_41, eye_lmk_x_42, eye_lmk_x_43, eye_lmk_x_44, eye_lmk_x_45, eye_lmk_x_46, eye_lmk_x_47, eye_lmk_x_48, eye_lmk_x_49, eye_lmk_x_50, eye_lmk_x_51, eye_lmk_x_52, eye_lmk_x_53, eye_lmk_x_54, eye_lmk_x_55, eye_lmk_y_0, eye_lmk_y_1, eye_lmk_y_2, eye_lmk_y_3, eye_lmk_y_4, eye_lmk_y_5, eye_lmk_y_6, eye_lmk_y_7, eye_lmk_y_8, eye_lmk_y_9, eye_lmk_y_10, eye_lmk_y_11, eye_lmk_y_12, eye_lmk_y_13, eye_lmk_y_14, eye_lmk_y_15, eye_lmk_y_16, eye_lmk_y_17, eye_lmk_y_18, eye_lmk_y_19, eye_lmk_y_20, eye_lmk_y_21, eye_lmk_y_22, eye_lmk_y_23, eye_lmk_y_24, eye_lmk_y_25, eye_lmk_y_26, eye_lmk_y_27, eye_lmk_y_28, eye_lmk_y_29, eye_lmk_y_30, eye_lmk_y_31, eye_lmk_y_32, eye_lmk_y_33, eye_lmk_y_34, eye_lmk_y_35, eye_lmk_y_36, eye_lmk_y_37, eye_lmk_y_38, eye_lmk_y_39, eye_lmk_y_40, eye_lmk_y_41, eye_lmk_y_42, eye_lmk_y_43, eye_lmk_y_44, eye_lmk_y_45, eye_lmk_y_46, eye_lmk_y_47, eye_lmk_y_48, eye_lmk_y_49, eye_lmk_y_50, eye_lmk_y_51, eye_lmk_y_52, eye_lmk_y_53, eye_lmk_y_54, eye_lmk_y_55, eye_lmk_X_0, eye_lmk_X_1, eye_lmk_X_2, eye_lmk_X_3, eye_lmk_X_4, eye_lmk_X_5, eye_lmk_X_6, eye_lmk_X_7, eye_lmk_X_8, eye_lmk_X_9, eye_lmk_X_10, eye_lmk_X_11, eye_lmk_X_12, eye_lmk_X_13, eye_lmk_X_14, eye_lmk_X_15, eye_lmk_X_16, eye_lmk_X_17, eye_lmk_X_18, eye_lmk_X_19, eye_lmk_X_20, eye_lmk_X_21, eye_lmk_X_22, eye_lmk_X_23, eye_lmk_X_24, eye_lmk_X_25, eye_lmk_X_26, eye_lmk_X_27, eye_lmk_X_28, eye_lmk_X_29, eye_lmk_X_30, eye_lmk_X_31, eye_lmk_X_32, eye_lmk_X_33, eye_lmk_X_34, eye_lmk_X_35, eye_lmk_X_36, eye_lmk_X_37, eye_lmk_X_38, eye_lmk_X_39, eye_lmk_X_40, eye_lmk_X_41, eye_lmk_X_42, eye_lmk_X_43, eye_lmk_X_44, eye_lmk_X_45, eye_lmk_X_46, eye_lmk_X_47, eye_lmk_X_48, eye_lmk_X_49, eye_lmk_X_50, eye_lmk_X_51, eye_lmk_X_52, eye_lmk_X_53, eye_lmk_X_54, eye_lmk_X_55, eye_lmk_Y_0, eye_lmk_Y_1, eye_lmk_Y_2, eye_lmk_Y_3, eye_lmk_Y_4, eye_lmk_Y_5, eye_lmk_Y_6, eye_lmk_Y_7, eye_lmk_Y_8, eye_lmk_Y_9, eye_lmk_Y_10, eye_lmk_Y_11, eye_lmk_Y_12, eye_lmk_Y_13, eye_lmk_Y_14, eye_lmk_Y_15, eye_lmk_Y_16, eye_lmk_Y_17, eye_lmk_Y_18, eye_lmk_Y_19, eye_lmk_Y_20, eye_lmk_Y_21, eye_lmk_Y_22, eye_lmk_Y_23, eye_lmk_Y_24, eye_lmk_Y_25, eye_lmk_Y_26, eye_lmk_Y_27, eye_lmk_Y_28, eye_lmk_Y_29, eye_lmk_Y_30, eye_lmk_Y_31, eye_lmk_Y_32, eye_lmk_Y_33, eye_lmk_Y_34, eye_lmk_Y_35, eye_lmk_Y_36, eye_lmk_Y_37, eye_lmk_Y_38, eye_lmk_Y_39, eye_lmk_Y_40, eye_lmk_Y_41, eye_lmk_Y_42, eye_lmk_Y_43, eye_lmk_Y_44, eye_lmk_Y_45, eye_lmk_Y_46, eye_lmk_Y_47, eye_lmk_Y_48, eye_lmk_Y_49, eye_lmk_Y_50, eye_lmk_Y_51, eye_lmk_Y_52, eye_lmk_Y_53, eye_lmk_Y_54, eye_lmk_Y_55, eye_lmk_Z_0, eye_lmk_Z_1, eye_lmk_Z_2, eye_lmk_Z_3, eye_lmk_Z_4, eye_lmk_Z_5, eye_lmk_Z_6, eye_lmk_Z_7, eye_lmk_Z_8, eye_lmk_Z_9, eye_lmk_Z_10, eye_lmk_Z_11, eye_lmk_Z_12, eye_lmk_Z_13, eye_lmk_Z_14, eye_lmk_Z_15, eye_lmk_Z_16, eye_lmk_Z_17, eye_lmk_Z_18, eye_lmk_Z_19, eye_lmk_Z_20, eye_lmk_Z_21, eye_lmk_Z_22, eye_lmk_Z_23, eye_lmk_Z_24, eye_lmk_Z_25, eye_lmk_Z_26, eye_lmk_Z_27, eye_lmk_Z_28, eye_lmk_Z_29, eye_lmk_Z_30, eye_lmk_Z_31, eye_lmk_Z_32, eye_lmk_Z_33, eye_lmk_Z_34, eye_lmk_Z_35, eye_lmk_Z_36, eye_lmk_Z_37, eye_lmk_Z_38, eye_lmk_Z_39, eye_lmk_Z_40, eye_lmk_Z_41, eye_lmk_Z_42, eye_lmk_Z_43, eye_lmk_Z_44, eye_lmk_Z_45, eye_lmk_Z_46, eye_lmk_Z_47, eye_lmk_Z_48, eye_lmk_Z_49, eye_lmk_Z_50, eye_lmk_Z_51, eye_lmk_Z_52, eye_lmk_Z_53, eye_lmk_Z_54, eye_lmk_Z_55, pose_Tx, pose_Ty, pose_Tz, pose_Rx, pose_Ry, pose_Rz, x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, y_0, y_1, y_2, y_3, y_4, y_5, y_6, y_7, y_8, y_9, y_10, y_11, y_12, y_13, y_14, y_15, y_16, y_17, y_18, y_19, y_20, y_21, y_22, y_23, y_24, y_25, y_26, y_27, y_28, y_29, y_30, y_31, y_32, y_33, y_34, y_35, y_36, y_37, y_38, y_39, y_40, y_41, y_42, y_43, y_44, y_45, y_46, y_47, y_48, y_49, y_50, y_51, y_52, y_53, y_54, y_55, y_56, y_57, y_58, y_59, y_60, y_61, y_62, y_63, y_64, y_65, y_66, y_67, X_0, X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9, X_10, X_11, X_12, X_13, X_14, X_15, X_16, X_17, X_18, X_19, X_20, X_21, X_22, X_23, X_24, X_25, X_26, X_27, X_28, X_29, X_30, X_31, X_32, X_33, X_34, X_35, X_36, X_37, X_38, X_39, X_40, X_41, X_42, X_43, X_44, X_45, X_46, X_47, X_48, X_49, X_50, X_51, X_52, X_53, X_54, X_55, X_56, X_57, X_58, X_59, X_60, X_61, X_62, X_63, X_64, X_65, X_66, X_67, Y_0, Y_1, Y_2, Y_3, Y_4, Y_5, Y_6, Y_7, Y_8, Y_9, Y_10, Y_11, Y_12, Y_13, Y_14, Y_15, Y_16, Y_17, Y_18, Y_19, Y_20, Y_21, Y_22, Y_23, Y_24, Y_25, Y_26, Y_27, Y_28, Y_29, Y_30, Y_31, Y_32, Y_33, Y_34, Y_35, Y_36, Y_37, Y_38, Y_39, Y_40, Y_41, Y_42, Y_43, Y_44, Y_45, Y_46, Y_47, Y_48, Y_49, Y_50, Y_51, Y_52, Y_53, Y_54, Y_55, Y_56, Y_57, Y_58, Y_59, Y_60, Y_61, Y_62, Y_63, Y_64, Y_65, Y_66, Y_67, Z_0, Z_1, Z_2, Z_3, Z_4, Z_5, Z_6, Z_7, Z_8, Z_9, Z_10, Z_11, Z_12, Z_13, Z_14, Z_15, Z_16, Z_17, Z_18, Z_19, Z_20, Z_21, Z_22, Z_23, Z_24, Z_25, Z_26, Z_27, Z_28, Z_29, Z_30, Z_31, Z_32, Z_33, Z_34, Z_35, Z_36, Z_37, Z_38, Z_39, Z_40, Z_41, Z_42, Z_43, Z_44, Z_45, Z_46, Z_47, Z_48, Z_49, Z_50, Z_51, Z_52, Z_53, Z_54, Z_55, Z_56, Z_57, Z_58, Z_59, Z_60, Z_61, Z_62, Z_63, Z_64, Z_65, Z_66, Z_67, p_scale, p_rx, p_ry, p_rz, p_tx, p_ty, p_0, p_1, p_2, p_3, p_4, p_5, p_6, p_7, p_8, p_9, p_10, p_11, p_12, p_13, p_14, p_15, p_16, p_17, p_18, p_19, p_20, p_21, p_22, p_23, p_24, p_25, p_26, p_27, p_28, p_29, p_30, p_31, p_32, p_33, AU01_r, AU02_r, AU04_r, AU05_r, AU06_r, AU07_r, AU09_r, AU10_r, AU12_r, AU14_r, AU15_r, AU17_r, AU20_r, AU23_r, AU25_r, AU26_r, AU45_r, AU01_c, AU02_c, AU04_c, AU05_c, AU06_c, AU07_c, AU09_c, AU10_c, AU12_c, AU14_c, AU15_c, AU17_c, AU20_c, AU23_c, AU25_c, AU26_c, AU28_c, AU45_c'.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veryfying...\n",
    "n=10\n",
    "for i in range(len(col)):\n",
    "    if col[i]!=columns[i]:\n",
    "        print(i, col[i], columns[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datalodaer.py, model.py test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataloader import Path_labels, OpenFace_DataLoader\n",
    "from model import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_labels=Path_labels(pd.read_csv(r\"C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels.csv\", index_col=0)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n",
      "c:\\GitHub\\Smart-Education\\EngaementModel\\dataloader.py:198: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_sample=pd.read_csv(labels[-1], sep='[,][ ]+').sample(n=n, frac=None, random_state=None) #use global seed\n"
     ]
    }
   ],
   "source": [
    "trainloader=OpenFace_DataLoader(n=10,\n",
    "                                path_labels=train_path_labels,\n",
    "                                batch_size=500,\n",
    "                                feature_set=None,\n",
    "                                y_col=['Engagement'],\n",
    "                                seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader.to('cuda')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del MLP\n",
    "from model import MLP\n",
    "import torch\n",
    "from os.path import join as ospj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "D_in=len(OpenFace_DataLoader.columns)-len([\n",
    "    'frame', 'face_id', 'timestamp', \n",
    "    'confidence', 'success', 'Boredom', \n",
    "    'Engagement', 'Confusion', 'Frustration'])\n",
    "print(D_in)\n",
    "model=MLP([D_in, 256, 64, 16, 4, 1], \n",
    "            n_classes=1,\n",
    "            loss_function='CrossEntropyLoss', loss_function_params=dict(),\n",
    "            optimizer='Adam', optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n",
    "            af='ReLU', af_params=dict(),\n",
    "            af_fin='Sigmoid', af_fin_params=dict(),\n",
    "            attach_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub\\Smart-Education\\EngaementModel\\TrainTest.ipynb Cell 26\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m.\u001b[39;49mtrain(trainloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, attach_label_onehot\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, attach_label_binarize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pred\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtest(trainloader, attach_label_onehot\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, attach_label_binarize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Smart-Education/EngaementModel/TrainTest.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     labels\u001b[39m=\u001b[39m[]\n",
      "File \u001b[1;32mc:\\GitHub\\Smart-Education\\EngaementModel\\model.py:76\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, dataLoader, epochs, attach_label_onehot, attach_label_binarize)\u001b[0m\n\u001b[0;32m     74\u001b[0m     label\u001b[39m=\u001b[39m(label\u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m)\u001b[39m.\u001b[39mint()\u001b[39m.\u001b[39mlong()\n\u001b[0;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 76\u001b[0m output\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m(x)\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m     78\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\GitHub\\Smart-Education\\EngaementModel\\model.py:63\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattach_softmax:\n\u001b[1;32m---> 63\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator(x))\n\u001b[0;32m     64\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator(x)\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "torch.manual_seed(0)\n",
    "for i in range(50):\n",
    "    model.train(trainloader, epochs=100, attach_label_onehot=False, attach_label_binarize=True)\n",
    "    pred=model.test(trainloader, attach_label_onehot=False, attach_label_binarize=True)\n",
    "    labels=[]\n",
    "    for _, y in trainloader:\n",
    "        labels+=y.detach().cpu()\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc=accuracy_score(labels>=2.0, pred.detach().cpu().numpy()>=0.5)\n",
    "    print(i, acc, sep='\\t')\n",
    "    if acc>0.8:\n",
    "        torch.save(model, ospj(path, f'MLP_clf_CE_ep{(i+1)*100}'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf - BCE model (trained with 4-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "D_in=len(OpenFace_DataLoader.columns)-len([\n",
    "    'frame', 'face_id', 'timestamp', \n",
    "    'confidence', 'success', 'Boredom', \n",
    "    'Engagement', 'Confusion', 'Frustration'])\n",
    "print(D_in)\n",
    "model=MLP([D_in, 256, 64, 16, 4], \n",
    "            n_classes=4,\n",
    "            loss_function='BCELoss', loss_function_params=dict(),\n",
    "            optimizer='Adam', optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n",
    "            af='ReLU', af_params=dict(),\n",
    "            af_fin='Sigmoid', af_fin_params=dict(),\n",
    "            attach_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "torch.manual_seed(0)\n",
    "for i in range(50):\n",
    "    model.train(trainloader, epochs=100, attach_label_onehot=True, attach_label_binarize=False)\n",
    "    pred=model.test(trainloader, attach_label_onehot=True, attach_label_binarize=False)\n",
    "    labels=[]\n",
    "    for _, y in trainloader:\n",
    "        labels+=y.detach().cpu()\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc=accuracy_score(labels, pred.detach().cpu().argmax(dim=1).numpy())\n",
    "    acc_b=accuracy_score(labels>=2.0, pred.detach().cpu().argmax(dim=1).numpy()>=2.0)\n",
    "    print(i, acc, acc_b, sep='\\t')\n",
    "    # [[0, 1, 2],\n",
    "    #  [1, 2, 3]]\n",
    "    # argmax(dim=0) -> [1, 1, 1]\n",
    "    # argmax(dim=1) -> [2, 2]\n",
    "    if acc>0.8 or acc_b>0.8:\n",
    "        torch.save(model, ospj(path, f'MLP_clf_BCE_ep{(i+1)*100}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4316/2504607172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressor approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from dataloader import Path_labels, OpenFace_DataLoader\n",
    "# from model import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path_labels=Path_labels(pd.read_csv(r\"C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels.csv\", index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader=OpenFace_DataLoader(n=10,\n",
    "#                                 path_labels=train_path_labels,\n",
    "#                                 batch_size=500,\n",
    "#                                 feature_set=None,\n",
    "#                                 y_col=['Engagement'],\n",
    "#                                 seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del MLP\n",
    "from model import MLPRegressor\n",
    "import torch\n",
    "from os.path import join as ospj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "D_in=len(OpenFace_DataLoader.columns)-len([\n",
    "    'frame', 'face_id', 'timestamp', \n",
    "    'confidence', 'success', 'Boredom', \n",
    "    'Engagement', 'Confusion', 'Frustration'])\n",
    "print(D_in)\n",
    "model=MLPRegressor([D_in, 256, 64, 16, 4, 1], \n",
    "            n_classes=1,\n",
    "            loss_function='MSELoss', loss_function_params=dict(),\n",
    "            optimizer='Adam', optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n",
    "            af='ReLU', af_params=dict(),\n",
    "            af_fin='Tanh', af_fin_params=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.9319773805180591\n",
      "1\t0.9062568405691354\n",
      "2\t0.9105435972272893\n",
      "3\t0.8992520977745349\n",
      "4\t0.9060744253921926\n",
      "5\t0.9023713973002554\n",
      "6\t0.9089930682232762\n",
      "7\t0.9161255016417366\n",
      "8\t0.896515870120394\n",
      "9\t0.8964429040496169\n",
      "10\t0.8710142283838015\n",
      "11\t0.8800072966070777\n",
      "12\t0.9026632615833637\n",
      "13\t0.876541408245166\n",
      "14\t0.8856439255746078\n",
      "15\t0.898321780372127\n",
      "16\t0.8761583363735863\n",
      "17\t0.8828712148850785\n",
      "18\t0.8798431229478293\n",
      "19\t0.8660525355709595\n",
      "20\t0.8739511127325793\n",
      "21\t0.8721087194454579\n"
     ]
    }
   ],
   "source": [
    "path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "torch.manual_seed(0)\n",
    "for i in range(50):\n",
    "    model.train(trainloader, epochs=100)\n",
    "    pred=model.test(trainloader)\n",
    "    labels=[]\n",
    "    for _, y in trainloader:\n",
    "        labels+=y.detach().cpu()\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc=accuracy_score(np.array(labels)>=2.0, pred.detach().cpu().numpy()>=2.0)\n",
    "    print(i, acc, sep='\\t')\n",
    "    if acc>0.8:\n",
    "        if True:\n",
    "            torch.save(model, ospj(path, f'MLP_reg_ep{(i+1)*100}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6432/2504607172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressor approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tpxdk\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\data.py:119: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model=XGBRegressor(verbosity=0)\n",
    "trainloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()[:, 1]\n",
    "    model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5976727272727272"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()[:, 1]\n",
    "    pred=model.predict(X)\n",
    "    eval.append(np.sum((Y-pred)<0.5)/len(Y))\n",
    "\n",
    "plt.plot(np.vstack(eval).ravel())\n",
    "np.mean(np.vstack(eval).ravel())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tpxdk\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "trainloader.to('cpu')\n",
    "model=XGBClassifier(random_state=0)\n",
    "# models={\n",
    "#     '0':XGBClassifier(random_state=0),\n",
    "#     '1':XGBClassifier(random_state=0),\n",
    "#     '2':XGBClassifier(random_state=0),\n",
    "#     '3':XGBClassifier(random_state=0)\n",
    "# }\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=one_hot(y).numpy()[:, 1]\n",
    "    model.fit(X, Y[:, 1])\n",
    "    # models['0'].fit(X, Y[:, 0])\n",
    "    # models['1'].fit(X, Y[:, 1])\n",
    "    # models['2'].fit(X, Y[:, 2])\n",
    "    # models['3'].fit(X, Y[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 1.   , 0.142, 0.138],\n",
       "       [1.   , 1.   , 0.152, 0.118],\n",
       "       [1.   , 0.94 , 0.492, 0.384],\n",
       "       [1.   , 0.92 , 0.518, 0.628],\n",
       "       [1.   , 0.94 , 0.644, 0.694],\n",
       "       [1.   , 0.98 , 0.668, 0.754],\n",
       "       [1.   , 0.94 , 0.508, 0.576],\n",
       "       [1.   , 1.   , 0.658, 0.72 ],\n",
       "       [1.   , 1.   , 0.524, 0.62 ],\n",
       "       [1.   , 1.   , 0.63 , 0.74 ],\n",
       "       [1.   , 0.96 , 0.516, 0.57 ],\n",
       "       [1.   , 1.   , 0.414, 0.4  ],\n",
       "       [1.   , 1.   , 0.484, 0.496],\n",
       "       [0.98 , 0.96 , 0.41 , 0.47 ],\n",
       "       [1.   , 0.98 , 0.77 , 0.8  ],\n",
       "       [1.   , 0.96 , 0.432, 0.626],\n",
       "       [0.98 , 0.9  , 0.432, 0.644],\n",
       "       [0.96 , 0.94 , 0.448, 0.458],\n",
       "       [1.   , 0.9  , 0.454, 0.39 ],\n",
       "       [0.96 , 0.88 , 0.414, 0.484],\n",
       "       [0.96 , 0.9  , 0.56 , 0.692],\n",
       "       [0.98 , 1.   , 0.48 , 0.46 ],\n",
       "       [1.   , 0.96 , 0.678, 0.626],\n",
       "       [1.   , 1.   , 0.48 , 0.48 ],\n",
       "       [1.   , 0.94 , 0.486, 0.52 ],\n",
       "       [1.   , 0.98 , 0.538, 0.574],\n",
       "       [1.   , 0.96 , 0.596, 0.664],\n",
       "       [1.   , 1.   , 0.578, 0.574],\n",
       "       [1.   , 1.   , 0.624, 0.592],\n",
       "       [1.   , 0.94 , 0.54 , 0.48 ],\n",
       "       [0.98 , 0.98 , 0.48 , 0.436],\n",
       "       [1.   , 1.   , 0.6  , 0.6  ],\n",
       "       [1.   , 0.978, 0.45 , 0.46 ],\n",
       "       [1.   , 0.922, 0.488, 0.574],\n",
       "       [1.   , 0.948, 0.45 , 0.552],\n",
       "       [1.   , 0.944, 0.378, 0.388],\n",
       "       [1.   , 0.98 , 0.408, 0.42 ],\n",
       "       [0.98 , 0.98 , 0.512, 0.538],\n",
       "       [0.98 , 0.92 , 0.412, 0.296],\n",
       "       [1.   , 1.   , 0.38 , 0.38 ],\n",
       "       [1.   , 0.96 , 0.42 , 0.38 ],\n",
       "       [1.   , 0.96 , 0.398, 0.438],\n",
       "       [1.   , 0.86 , 0.524, 0.74 ],\n",
       "       [1.   , 0.96 , 0.548, 0.66 ],\n",
       "       [1.   , 0.94 , 0.518, 0.6  ],\n",
       "       [1.   , 1.   , 0.674, 0.674],\n",
       "       [0.86 , 0.96 , 0.44 , 0.614],\n",
       "       [1.   , 0.98 , 0.43 , 0.282],\n",
       "       [1.   , 1.   , 0.568, 0.52 ],\n",
       "       [1.   , 0.96 , 0.54 , 0.542],\n",
       "       [0.98 , 1.   , 0.548, 0.658],\n",
       "       [1.   , 0.98 , 0.518, 0.454],\n",
       "       [1.   , 0.98 , 0.524, 0.516],\n",
       "       [1.   , 1.   , 0.62 , 0.546],\n",
       "       [1.   , 0.94 , 0.334, 0.268],\n",
       "       [1.   , 0.98 , 0.744, 0.738],\n",
       "       [1.   , 0.98 , 0.402, 0.418],\n",
       "       [1.   , 1.   , 0.514, 0.4  ],\n",
       "       [1.   , 1.   , 0.808, 0.664],\n",
       "       [1.   , 0.98 , 0.658, 0.57 ],\n",
       "       [1.   , 0.98 , 0.248, 0.252],\n",
       "       [0.98 , 0.92 , 0.508, 0.488],\n",
       "       [1.   , 0.98 , 0.536, 0.542],\n",
       "       [1.   , 0.98 , 0.382, 0.378],\n",
       "       [1.   , 1.   , 0.554, 0.558],\n",
       "       [1.   , 0.92 , 0.586, 0.502],\n",
       "       [1.   , 0.92 , 0.464, 0.334],\n",
       "       [1.   , 0.9  , 0.682, 0.622],\n",
       "       [1.   , 0.98 , 0.454, 0.404],\n",
       "       [1.   , 0.96 , 0.666, 0.74 ],\n",
       "       [1.   , 0.98 , 0.512, 0.542],\n",
       "       [1.   , 0.978, 0.708, 0.692],\n",
       "       [1.   , 0.962, 0.78 , 0.784],\n",
       "       [1.   , 1.   , 0.554, 0.556],\n",
       "       [1.   , 0.98 , 0.292, 0.322],\n",
       "       [1.   , 0.98 , 0.32 , 0.3  ],\n",
       "       [0.96 , 0.88 , 0.646, 0.606],\n",
       "       [1.   , 0.9  , 0.52 , 0.552],\n",
       "       [1.   , 0.88 , 0.61 , 0.722],\n",
       "       [1.   , 0.9  , 0.676, 0.77 ],\n",
       "       [1.   , 1.   , 0.444, 0.458],\n",
       "       [1.   , 0.92 , 0.616, 0.602],\n",
       "       [1.   , 1.   , 0.59 , 0.554],\n",
       "       [1.   , 0.98 , 0.578, 0.516],\n",
       "       [1.   , 0.98 , 0.61 , 0.74 ],\n",
       "       [1.   , 0.98 , 0.56 , 0.658],\n",
       "       [0.96 , 0.9  , 0.422, 0.49 ],\n",
       "       [0.92 , 0.94 , 0.484, 0.556],\n",
       "       [1.   , 0.94 , 0.55 , 0.564],\n",
       "       [1.   , 0.98 , 0.512, 0.54 ],\n",
       "       [1.   , 0.98 , 0.564, 0.446],\n",
       "       [1.   , 1.   , 0.694, 0.52 ],\n",
       "       [1.   , 0.94 , 0.472, 0.494],\n",
       "       [1.   , 1.   , 0.378, 0.32 ],\n",
       "       [1.   , 1.   , 0.728, 0.734],\n",
       "       [0.98 , 0.98 , 0.77 , 0.76 ],\n",
       "       [1.   , 0.94 , 0.562, 0.596],\n",
       "       [1.   , 1.   , 0.6  , 0.66 ],\n",
       "       [1.   , 0.98 , 0.608, 0.67 ],\n",
       "       [1.   , 0.98 , 0.624, 0.622],\n",
       "       [0.94 , 0.72 , 0.534, 0.226],\n",
       "       [0.98 , 0.9  , 0.34 , 0.22 ],\n",
       "       [1.   , 0.86 , 0.414, 0.348],\n",
       "       [1.   , 0.9  , 0.39 , 0.258],\n",
       "       [1.   , 0.9  , 0.274, 0.272],\n",
       "       [1.   , 0.98 , 0.368, 0.332],\n",
       "       [1.   , 0.96 , 0.286, 0.24 ],\n",
       "       [1.   , 1.   , 0.65 , 0.62 ],\n",
       "       [1.   , 1.   , 0.7  , 0.702],\n",
       "       [1.   , 1.   , 1.   , 1.   ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "list_acc=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=one_hot(y).numpy()[:, 1]\n",
    "    pred=[]\n",
    "    pred.append(models['0'].predict(X))\n",
    "    pred.append(models['1'].predict(X))\n",
    "    pred.append(models['2'].predict(X))\n",
    "    pred.append(models['3'].predict(X))\n",
    "    acc=[]\n",
    "    for i, p in enumerate(pred):\n",
    "        acc.append(accuracy_score(Y[:, i], p))\n",
    "    list_acc.append(acc)\n",
    "np.vstack(list_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40fc240bea52273cd1a1858a71b7744abb2d3b41121723fab477901189220d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
