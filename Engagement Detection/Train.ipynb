{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os.path import join as ospj\n",
    "from os.path import exists as osex\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           ClipID  Boredom  Engagement  Confusion  Frustration      f_name  \\\n",
       " 0  1100011002.avi        0           2          0            0  1100011002   \n",
       " 1  1100011003.avi        0           2          0            0  1100011003   \n",
       " 2  1100011004.avi        0           3          0            0  1100011004   \n",
       " \n",
       "                                                 path  \n",
       " 0  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  \n",
       " 1  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  \n",
       " 2  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  ,\n",
       "            ClipID  Boredom  Engagement  Confusion  Frustration      f_name  \\\n",
       " 0  5000441001.avi        1           2          0            0  5000441001   \n",
       " 1  5000441002.avi        0           2          0            0  5000441002   \n",
       " 2  5000441003.avi        1           2          0            0  5000441003   \n",
       " \n",
       "                                                 path  \n",
       " 0  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  \n",
       " 1  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  \n",
       " 2  C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sor...  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels=pd.read_csv(r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels_train.csv', index_col=0)\n",
    "df_test_labels=pd.read_csv(r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels_test.csv', index_col=0)\n",
    "df_train_labels[:3], df_test_labels[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building column names in dataloader..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['frame',\n",
    "                  'face_id',\n",
    "                  'timestamp',\n",
    "                  'confidence',\n",
    "                  'success',\n",
    "                  'gaze_0_x', 'gaze_0_y', 'gaze_0_z',\n",
    "                  'gaze_1_x', 'gaze_1_y', 'gaze_1_z',\n",
    "                  'gaze_angle_x', 'gaze_angle_y', \n",
    "                  'eye_lmk_x_0', 'eye_lmk_x_1', 'eye_lmk_x_2', 'eye_lmk_x_3', 'eye_lmk_x_4',\n",
    "                  'eye_lmk_x_5', 'eye_lmk_x_6', 'eye_lmk_x_7', 'eye_lmk_x_8', 'eye_lmk_x_9',\n",
    "                  'eye_lmk_x_10', 'eye_lmk_x_11', 'eye_lmk_x_12', 'eye_lmk_x_13', 'eye_lmk_x_14',\n",
    "                  'eye_lmk_x_15', 'eye_lmk_x_16', 'eye_lmk_x_17', 'eye_lmk_x_18', 'eye_lmk_x_19',\n",
    "                  'eye_lmk_x_20', 'eye_lmk_x_21', 'eye_lmk_x_22', 'eye_lmk_x_23', 'eye_lmk_x_24',\n",
    "                  'eye_lmk_x_25', 'eye_lmk_x_26', 'eye_lmk_x_27', 'eye_lmk_x_28', 'eye_lmk_x_29',\n",
    "                  'eye_lmk_x_30', 'eye_lmk_x_31', 'eye_lmk_x_32', 'eye_lmk_x_33', 'eye_lmk_x_34',\n",
    "                  'eye_lmk_x_35', 'eye_lmk_x_36', 'eye_lmk_x_37', 'eye_lmk_x_38', 'eye_lmk_x_39',\n",
    "                  'eye_lmk_x_40', 'eye_lmk_x_41', 'eye_lmk_x_42', 'eye_lmk_x_43', 'eye_lmk_x_44',\n",
    "                  'eye_lmk_x_45', 'eye_lmk_x_46', 'eye_lmk_x_47', 'eye_lmk_x_48', 'eye_lmk_x_49',\n",
    "                  'eye_lmk_x_50', 'eye_lmk_x_51', 'eye_lmk_x_52', 'eye_lmk_x_53', 'eye_lmk_x_54',\n",
    "                  'eye_lmk_x_55',\n",
    "                  'eye_lmk_y_0', 'eye_lmk_y_1', 'eye_lmk_y_2', 'eye_lmk_y_3', 'eye_lmk_y_4',\n",
    "                  'eye_lmk_y_5', 'eye_lmk_y_6', 'eye_lmk_y_7', 'eye_lmk_y_8', 'eye_lmk_y_9',\n",
    "                  'eye_lmk_y_10', 'eye_lmk_y_11', 'eye_lmk_y_12', 'eye_lmk_y_13', 'eye_lmk_y_14',\n",
    "                  'eye_lmk_y_15', 'eye_lmk_y_16', 'eye_lmk_y_17', 'eye_lmk_y_18', 'eye_lmk_y_19',\n",
    "                  'eye_lmk_y_20', 'eye_lmk_y_21', 'eye_lmk_y_22', 'eye_lmk_y_23', 'eye_lmk_y_24',\n",
    "                  'eye_lmk_y_25', 'eye_lmk_y_26', 'eye_lmk_y_27', 'eye_lmk_y_28', 'eye_lmk_y_29',\n",
    "                  'eye_lmk_y_30', 'eye_lmk_y_31', 'eye_lmk_y_32', 'eye_lmk_y_33', 'eye_lmk_y_34',\n",
    "                  'eye_lmk_y_35', 'eye_lmk_y_36', 'eye_lmk_y_37', 'eye_lmk_y_38', 'eye_lmk_y_39',\n",
    "                  'eye_lmk_y_40', 'eye_lmk_y_41', 'eye_lmk_y_42', 'eye_lmk_y_43', 'eye_lmk_y_44',\n",
    "                  'eye_lmk_y_45', 'eye_lmk_y_46', 'eye_lmk_y_47', 'eye_lmk_y_48', 'eye_lmk_y_49',\n",
    "                  'eye_lmk_y_50', 'eye_lmk_y_51', 'eye_lmk_y_52', 'eye_lmk_y_53', 'eye_lmk_y_54',\n",
    "                  'eye_lmk_y_55',\n",
    "                  'eye_lmk_X_0', 'eye_lmk_X_1', 'eye_lmk_X_2', 'eye_lmk_X_3', 'eye_lmk_X_4', \n",
    "                  'eye_lmk_X_5', 'eye_lmk_X_6', 'eye_lmk_X_7', 'eye_lmk_X_8', 'eye_lmk_X_9',\n",
    "                  'eye_lmk_X_10', 'eye_lmk_X_11', 'eye_lmk_X_12', 'eye_lmk_X_13', 'eye_lmk_X_14',\n",
    "                  'eye_lmk_X_15', 'eye_lmk_X_16', 'eye_lmk_X_17', 'eye_lmk_X_18', 'eye_lmk_X_19',\n",
    "                  'eye_lmk_X_20', 'eye_lmk_X_21', 'eye_lmk_X_22', 'eye_lmk_X_23', 'eye_lmk_X_24',\n",
    "                  'eye_lmk_X_25', 'eye_lmk_X_26', 'eye_lmk_X_27', 'eye_lmk_X_28', 'eye_lmk_X_29',\n",
    "                  'eye_lmk_X_30', 'eye_lmk_X_31', 'eye_lmk_X_32', 'eye_lmk_X_33', 'eye_lmk_X_34',\n",
    "                  'eye_lmk_X_35', 'eye_lmk_X_36', 'eye_lmk_X_37', 'eye_lmk_X_38', 'eye_lmk_X_39',\n",
    "                  'eye_lmk_X_40', 'eye_lmk_X_41', 'eye_lmk_X_42', 'eye_lmk_X_43', 'eye_lmk_X_44',\n",
    "                  'eye_lmk_X_45', 'eye_lmk_X_46', 'eye_lmk_X_47', 'eye_lmk_X_48', 'eye_lmk_X_49',\n",
    "                  'eye_lmk_X_50', 'eye_lmk_X_51', 'eye_lmk_X_52', 'eye_lmk_X_53', 'eye_lmk_X_54', \n",
    "                  'eye_lmk_X_55', \n",
    "                  'eye_lmk_Y_0', 'eye_lmk_Y_1', 'eye_lmk_Y_2', 'eye_lmk_Y_3', 'eye_lmk_Y_4',\n",
    "                  'eye_lmk_Y_5', 'eye_lmk_Y_6', 'eye_lmk_Y_7', 'eye_lmk_Y_8', 'eye_lmk_Y_9',\n",
    "                  'eye_lmk_Y_10', 'eye_lmk_Y_11', 'eye_lmk_Y_12', 'eye_lmk_Y_13', 'eye_lmk_Y_14',\n",
    "                  'eye_lmk_Y_15', 'eye_lmk_Y_16', 'eye_lmk_Y_17', 'eye_lmk_Y_18', 'eye_lmk_Y_19',\n",
    "                  'eye_lmk_Y_20', 'eye_lmk_Y_21', 'eye_lmk_Y_22', 'eye_lmk_Y_23', 'eye_lmk_Y_24',\n",
    "                  'eye_lmk_Y_25', 'eye_lmk_Y_26', 'eye_lmk_Y_27', 'eye_lmk_Y_28', 'eye_lmk_Y_29',\n",
    "                  'eye_lmk_Y_30', 'eye_lmk_Y_31', 'eye_lmk_Y_32', 'eye_lmk_Y_33', 'eye_lmk_Y_34',\n",
    "                  'eye_lmk_Y_35', 'eye_lmk_Y_36', 'eye_lmk_Y_37', 'eye_lmk_Y_38', 'eye_lmk_Y_39',\n",
    "                  'eye_lmk_Y_40', 'eye_lmk_Y_41', 'eye_lmk_Y_42', 'eye_lmk_Y_43', 'eye_lmk_Y_44',\n",
    "                  'eye_lmk_Y_45', 'eye_lmk_Y_46', 'eye_lmk_Y_47', 'eye_lmk_Y_48', 'eye_lmk_Y_49',\n",
    "                  'eye_lmk_Y_50', 'eye_lmk_Y_51', 'eye_lmk_Y_52', 'eye_lmk_Y_53', 'eye_lmk_Y_54',\n",
    "                  'eye_lmk_Y_55', \n",
    "                  'eye_lmk_Z_0', 'eye_lmk_Z_1', 'eye_lmk_Z_2', 'eye_lmk_Z_3', 'eye_lmk_Z_4',\n",
    "                  'eye_lmk_Z_5', 'eye_lmk_Z_6', 'eye_lmk_Z_7', 'eye_lmk_Z_8', 'eye_lmk_Z_9', \n",
    "                  'eye_lmk_Z_10', 'eye_lmk_Z_11', 'eye_lmk_Z_12', 'eye_lmk_Z_13', 'eye_lmk_Z_14', \n",
    "                  'eye_lmk_Z_15', 'eye_lmk_Z_16', 'eye_lmk_Z_17', 'eye_lmk_Z_18', 'eye_lmk_Z_19',\n",
    "                  'eye_lmk_Z_20', 'eye_lmk_Z_21', 'eye_lmk_Z_22', 'eye_lmk_Z_23', 'eye_lmk_Z_24', \n",
    "                  'eye_lmk_Z_25', 'eye_lmk_Z_26', 'eye_lmk_Z_27', 'eye_lmk_Z_28', 'eye_lmk_Z_29',\n",
    "                  'eye_lmk_Z_30', 'eye_lmk_Z_31', 'eye_lmk_Z_32', 'eye_lmk_Z_33', 'eye_lmk_Z_34', \n",
    "                  'eye_lmk_Z_35', 'eye_lmk_Z_36', 'eye_lmk_Z_37', 'eye_lmk_Z_38', 'eye_lmk_Z_39',\n",
    "                  'eye_lmk_Z_40', 'eye_lmk_Z_41', 'eye_lmk_Z_42', 'eye_lmk_Z_43', 'eye_lmk_Z_44', \n",
    "                  'eye_lmk_Z_45', 'eye_lmk_Z_46', 'eye_lmk_Z_47', 'eye_lmk_Z_48', 'eye_lmk_Z_49', \n",
    "                  'eye_lmk_Z_50', 'eye_lmk_Z_51', 'eye_lmk_Z_52', 'eye_lmk_Z_53', 'eye_lmk_Z_54', \n",
    "                  'eye_lmk_Z_55', \n",
    "                  'pose_Tx', 'pose_Ty', 'pose_Tz', 'pose_Rx', 'pose_Ry', 'pose_Rz',\n",
    "                  'x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', \n",
    "                  'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19',\n",
    "                  'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29',\n",
    "                  'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', \n",
    "                  'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_49',\n",
    "                  'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59',\n",
    "                  'x_60', 'x_61', 'x_62', 'x_63', 'x_64', 'x_65', 'x_66', 'x_67',\n",
    "                  'y_0', 'y_1', 'y_2', 'y_3', 'y_4', 'y_5', 'y_6', 'y_7', 'y_8', 'y_9',\n",
    "                  'y_10', 'y_11', 'y_12', 'y_13', 'y_14', 'y_15', 'y_16', 'y_17', 'y_18', 'y_19', \n",
    "                  'y_20', 'y_21', 'y_22', 'y_23', 'y_24', 'y_25', 'y_26', 'y_27', 'y_28', 'y_29',\n",
    "                  'y_30', 'y_31', 'y_32', 'y_33', 'y_34', 'y_35', 'y_36', 'y_37', 'y_38', 'y_39',\n",
    "                  'y_40', 'y_41', 'y_42', 'y_43', 'y_44', 'y_45', 'y_46', 'y_47', 'y_48', 'y_49', \n",
    "                  'y_50', 'y_51', 'y_52', 'y_53', 'y_54', 'y_55', 'y_56', 'y_57', 'y_58', 'y_59', \n",
    "                  'y_60', 'y_61', 'y_62', 'y_63', 'y_64', 'y_65', 'y_66', 'y_67', \n",
    "                  'X_0', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', \n",
    "                  'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19', \n",
    "                  'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29', \n",
    "                  'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38', 'X_39', \n",
    "                  'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_47', 'X_48', 'X_49', \n",
    "                  'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56', 'X_57', 'X_58', 'X_59', \n",
    "                  'X_60', 'X_61', 'X_62', 'X_63', 'X_64', 'X_65', 'X_66', 'X_67', \n",
    "                  'Y_0', 'Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9',\n",
    "                  'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14', 'Y_15', 'Y_16', 'Y_17', 'Y_18', 'Y_19',\n",
    "                  'Y_20', 'Y_21', 'Y_22', 'Y_23', 'Y_24', 'Y_25', 'Y_26', 'Y_27', 'Y_28', 'Y_29', \n",
    "                  'Y_30', 'Y_31', 'Y_32', 'Y_33', 'Y_34', 'Y_35', 'Y_36', 'Y_37', 'Y_38', 'Y_39', \n",
    "                  'Y_40', 'Y_41', 'Y_42', 'Y_43', 'Y_44', 'Y_45', 'Y_46', 'Y_47', 'Y_48', 'Y_49', \n",
    "                  'Y_50', 'Y_51', 'Y_52', 'Y_53', 'Y_54', 'Y_55', 'Y_56', 'Y_57', 'Y_58', 'Y_59', \n",
    "                  'Y_60', 'Y_61', 'Y_62', 'Y_63', 'Y_64', 'Y_65', 'Y_66', 'Y_67',\n",
    "                  'Z_0', 'Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9',\n",
    "                  'Z_10', 'Z_11', 'Z_12', 'Z_13', 'Z_14', 'Z_15', 'Z_16', 'Z_17', 'Z_18', 'Z_19',\n",
    "                  'Z_20', 'Z_21', 'Z_22', 'Z_23', 'Z_24', 'Z_25', 'Z_26', 'Z_27', 'Z_28', 'Z_29',\n",
    "                  'Z_30', 'Z_31', 'Z_32', 'Z_33', 'Z_34', 'Z_35', 'Z_36', 'Z_37', 'Z_38', 'Z_39',\n",
    "                  'Z_40', 'Z_41', 'Z_42', 'Z_43', 'Z_44', 'Z_45', 'Z_46', 'Z_47', 'Z_48', 'Z_49',\n",
    "                  'Z_50', 'Z_51', 'Z_52', 'Z_53', 'Z_54', 'Z_55', 'Z_56', 'Z_57', 'Z_58', 'Z_59',\n",
    "                  'Z_60', 'Z_61', 'Z_62', 'Z_63', 'Z_64', 'Z_65', 'Z_66', 'Z_67',\n",
    "                  'p_scale', 'p_rx', 'p_ry', 'p_rz', 'p_tx', 'p_ty', \n",
    "                  'p_0', 'p_1', 'p_2', 'p_3', 'p_4', 'p_5', 'p_6', 'p_7', 'p_8', 'p_9', \n",
    "                  'p_10', 'p_11', 'p_12', 'p_13', 'p_14', 'p_15', 'p_16', 'p_17', 'p_18', 'p_19',\n",
    "                  'p_20', 'p_21', 'p_22', 'p_23', 'p_24', 'p_25', 'p_26', 'p_27', 'p_28', 'p_29', \n",
    "                  'p_30', 'p_31', 'p_32', 'p_33', \n",
    "                  'AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', \n",
    "                  'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', \n",
    "                  'AU45_r', \n",
    "                  'AU01_c', 'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c', \n",
    "                  'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c', 'AU26_c', \n",
    "                  'AU28_c', 'AU45_c'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='frame, face_id, timestamp, confidence, success, gaze_0_x, gaze_0_y, gaze_0_z, gaze_1_x, gaze_1_y, gaze_1_z, gaze_angle_x, gaze_angle_y, eye_lmk_x_0, eye_lmk_x_1, eye_lmk_x_2, eye_lmk_x_3, eye_lmk_x_4, eye_lmk_x_5, eye_lmk_x_6, eye_lmk_x_7, eye_lmk_x_8, eye_lmk_x_9, eye_lmk_x_10, eye_lmk_x_11, eye_lmk_x_12, eye_lmk_x_13, eye_lmk_x_14, eye_lmk_x_15, eye_lmk_x_16, eye_lmk_x_17, eye_lmk_x_18, eye_lmk_x_19, eye_lmk_x_20, eye_lmk_x_21, eye_lmk_x_22, eye_lmk_x_23, eye_lmk_x_24, eye_lmk_x_25, eye_lmk_x_26, eye_lmk_x_27, eye_lmk_x_28, eye_lmk_x_29, eye_lmk_x_30, eye_lmk_x_31, eye_lmk_x_32, eye_lmk_x_33, eye_lmk_x_34, eye_lmk_x_35, eye_lmk_x_36, eye_lmk_x_37, eye_lmk_x_38, eye_lmk_x_39, eye_lmk_x_40, eye_lmk_x_41, eye_lmk_x_42, eye_lmk_x_43, eye_lmk_x_44, eye_lmk_x_45, eye_lmk_x_46, eye_lmk_x_47, eye_lmk_x_48, eye_lmk_x_49, eye_lmk_x_50, eye_lmk_x_51, eye_lmk_x_52, eye_lmk_x_53, eye_lmk_x_54, eye_lmk_x_55, eye_lmk_y_0, eye_lmk_y_1, eye_lmk_y_2, eye_lmk_y_3, eye_lmk_y_4, eye_lmk_y_5, eye_lmk_y_6, eye_lmk_y_7, eye_lmk_y_8, eye_lmk_y_9, eye_lmk_y_10, eye_lmk_y_11, eye_lmk_y_12, eye_lmk_y_13, eye_lmk_y_14, eye_lmk_y_15, eye_lmk_y_16, eye_lmk_y_17, eye_lmk_y_18, eye_lmk_y_19, eye_lmk_y_20, eye_lmk_y_21, eye_lmk_y_22, eye_lmk_y_23, eye_lmk_y_24, eye_lmk_y_25, eye_lmk_y_26, eye_lmk_y_27, eye_lmk_y_28, eye_lmk_y_29, eye_lmk_y_30, eye_lmk_y_31, eye_lmk_y_32, eye_lmk_y_33, eye_lmk_y_34, eye_lmk_y_35, eye_lmk_y_36, eye_lmk_y_37, eye_lmk_y_38, eye_lmk_y_39, eye_lmk_y_40, eye_lmk_y_41, eye_lmk_y_42, eye_lmk_y_43, eye_lmk_y_44, eye_lmk_y_45, eye_lmk_y_46, eye_lmk_y_47, eye_lmk_y_48, eye_lmk_y_49, eye_lmk_y_50, eye_lmk_y_51, eye_lmk_y_52, eye_lmk_y_53, eye_lmk_y_54, eye_lmk_y_55, eye_lmk_X_0, eye_lmk_X_1, eye_lmk_X_2, eye_lmk_X_3, eye_lmk_X_4, eye_lmk_X_5, eye_lmk_X_6, eye_lmk_X_7, eye_lmk_X_8, eye_lmk_X_9, eye_lmk_X_10, eye_lmk_X_11, eye_lmk_X_12, eye_lmk_X_13, eye_lmk_X_14, eye_lmk_X_15, eye_lmk_X_16, eye_lmk_X_17, eye_lmk_X_18, eye_lmk_X_19, eye_lmk_X_20, eye_lmk_X_21, eye_lmk_X_22, eye_lmk_X_23, eye_lmk_X_24, eye_lmk_X_25, eye_lmk_X_26, eye_lmk_X_27, eye_lmk_X_28, eye_lmk_X_29, eye_lmk_X_30, eye_lmk_X_31, eye_lmk_X_32, eye_lmk_X_33, eye_lmk_X_34, eye_lmk_X_35, eye_lmk_X_36, eye_lmk_X_37, eye_lmk_X_38, eye_lmk_X_39, eye_lmk_X_40, eye_lmk_X_41, eye_lmk_X_42, eye_lmk_X_43, eye_lmk_X_44, eye_lmk_X_45, eye_lmk_X_46, eye_lmk_X_47, eye_lmk_X_48, eye_lmk_X_49, eye_lmk_X_50, eye_lmk_X_51, eye_lmk_X_52, eye_lmk_X_53, eye_lmk_X_54, eye_lmk_X_55, eye_lmk_Y_0, eye_lmk_Y_1, eye_lmk_Y_2, eye_lmk_Y_3, eye_lmk_Y_4, eye_lmk_Y_5, eye_lmk_Y_6, eye_lmk_Y_7, eye_lmk_Y_8, eye_lmk_Y_9, eye_lmk_Y_10, eye_lmk_Y_11, eye_lmk_Y_12, eye_lmk_Y_13, eye_lmk_Y_14, eye_lmk_Y_15, eye_lmk_Y_16, eye_lmk_Y_17, eye_lmk_Y_18, eye_lmk_Y_19, eye_lmk_Y_20, eye_lmk_Y_21, eye_lmk_Y_22, eye_lmk_Y_23, eye_lmk_Y_24, eye_lmk_Y_25, eye_lmk_Y_26, eye_lmk_Y_27, eye_lmk_Y_28, eye_lmk_Y_29, eye_lmk_Y_30, eye_lmk_Y_31, eye_lmk_Y_32, eye_lmk_Y_33, eye_lmk_Y_34, eye_lmk_Y_35, eye_lmk_Y_36, eye_lmk_Y_37, eye_lmk_Y_38, eye_lmk_Y_39, eye_lmk_Y_40, eye_lmk_Y_41, eye_lmk_Y_42, eye_lmk_Y_43, eye_lmk_Y_44, eye_lmk_Y_45, eye_lmk_Y_46, eye_lmk_Y_47, eye_lmk_Y_48, eye_lmk_Y_49, eye_lmk_Y_50, eye_lmk_Y_51, eye_lmk_Y_52, eye_lmk_Y_53, eye_lmk_Y_54, eye_lmk_Y_55, eye_lmk_Z_0, eye_lmk_Z_1, eye_lmk_Z_2, eye_lmk_Z_3, eye_lmk_Z_4, eye_lmk_Z_5, eye_lmk_Z_6, eye_lmk_Z_7, eye_lmk_Z_8, eye_lmk_Z_9, eye_lmk_Z_10, eye_lmk_Z_11, eye_lmk_Z_12, eye_lmk_Z_13, eye_lmk_Z_14, eye_lmk_Z_15, eye_lmk_Z_16, eye_lmk_Z_17, eye_lmk_Z_18, eye_lmk_Z_19, eye_lmk_Z_20, eye_lmk_Z_21, eye_lmk_Z_22, eye_lmk_Z_23, eye_lmk_Z_24, eye_lmk_Z_25, eye_lmk_Z_26, eye_lmk_Z_27, eye_lmk_Z_28, eye_lmk_Z_29, eye_lmk_Z_30, eye_lmk_Z_31, eye_lmk_Z_32, eye_lmk_Z_33, eye_lmk_Z_34, eye_lmk_Z_35, eye_lmk_Z_36, eye_lmk_Z_37, eye_lmk_Z_38, eye_lmk_Z_39, eye_lmk_Z_40, eye_lmk_Z_41, eye_lmk_Z_42, eye_lmk_Z_43, eye_lmk_Z_44, eye_lmk_Z_45, eye_lmk_Z_46, eye_lmk_Z_47, eye_lmk_Z_48, eye_lmk_Z_49, eye_lmk_Z_50, eye_lmk_Z_51, eye_lmk_Z_52, eye_lmk_Z_53, eye_lmk_Z_54, eye_lmk_Z_55, pose_Tx, pose_Ty, pose_Tz, pose_Rx, pose_Ry, pose_Rz, x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, y_0, y_1, y_2, y_3, y_4, y_5, y_6, y_7, y_8, y_9, y_10, y_11, y_12, y_13, y_14, y_15, y_16, y_17, y_18, y_19, y_20, y_21, y_22, y_23, y_24, y_25, y_26, y_27, y_28, y_29, y_30, y_31, y_32, y_33, y_34, y_35, y_36, y_37, y_38, y_39, y_40, y_41, y_42, y_43, y_44, y_45, y_46, y_47, y_48, y_49, y_50, y_51, y_52, y_53, y_54, y_55, y_56, y_57, y_58, y_59, y_60, y_61, y_62, y_63, y_64, y_65, y_66, y_67, X_0, X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9, X_10, X_11, X_12, X_13, X_14, X_15, X_16, X_17, X_18, X_19, X_20, X_21, X_22, X_23, X_24, X_25, X_26, X_27, X_28, X_29, X_30, X_31, X_32, X_33, X_34, X_35, X_36, X_37, X_38, X_39, X_40, X_41, X_42, X_43, X_44, X_45, X_46, X_47, X_48, X_49, X_50, X_51, X_52, X_53, X_54, X_55, X_56, X_57, X_58, X_59, X_60, X_61, X_62, X_63, X_64, X_65, X_66, X_67, Y_0, Y_1, Y_2, Y_3, Y_4, Y_5, Y_6, Y_7, Y_8, Y_9, Y_10, Y_11, Y_12, Y_13, Y_14, Y_15, Y_16, Y_17, Y_18, Y_19, Y_20, Y_21, Y_22, Y_23, Y_24, Y_25, Y_26, Y_27, Y_28, Y_29, Y_30, Y_31, Y_32, Y_33, Y_34, Y_35, Y_36, Y_37, Y_38, Y_39, Y_40, Y_41, Y_42, Y_43, Y_44, Y_45, Y_46, Y_47, Y_48, Y_49, Y_50, Y_51, Y_52, Y_53, Y_54, Y_55, Y_56, Y_57, Y_58, Y_59, Y_60, Y_61, Y_62, Y_63, Y_64, Y_65, Y_66, Y_67, Z_0, Z_1, Z_2, Z_3, Z_4, Z_5, Z_6, Z_7, Z_8, Z_9, Z_10, Z_11, Z_12, Z_13, Z_14, Z_15, Z_16, Z_17, Z_18, Z_19, Z_20, Z_21, Z_22, Z_23, Z_24, Z_25, Z_26, Z_27, Z_28, Z_29, Z_30, Z_31, Z_32, Z_33, Z_34, Z_35, Z_36, Z_37, Z_38, Z_39, Z_40, Z_41, Z_42, Z_43, Z_44, Z_45, Z_46, Z_47, Z_48, Z_49, Z_50, Z_51, Z_52, Z_53, Z_54, Z_55, Z_56, Z_57, Z_58, Z_59, Z_60, Z_61, Z_62, Z_63, Z_64, Z_65, Z_66, Z_67, p_scale, p_rx, p_ry, p_rz, p_tx, p_ty, p_0, p_1, p_2, p_3, p_4, p_5, p_6, p_7, p_8, p_9, p_10, p_11, p_12, p_13, p_14, p_15, p_16, p_17, p_18, p_19, p_20, p_21, p_22, p_23, p_24, p_25, p_26, p_27, p_28, p_29, p_30, p_31, p_32, p_33, AU01_r, AU02_r, AU04_r, AU05_r, AU06_r, AU07_r, AU09_r, AU10_r, AU12_r, AU14_r, AU15_r, AU17_r, AU20_r, AU23_r, AU25_r, AU26_r, AU45_r, AU01_c, AU02_c, AU04_c, AU05_c, AU06_c, AU07_c, AU09_c, AU10_c, AU12_c, AU14_c, AU15_c, AU17_c, AU20_c, AU23_c, AU25_c, AU26_c, AU28_c, AU45_c'.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datalodaer.py, model.py test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODELS=False #give True to save qualified models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataloader import Path_labels, OpenFace_DataLoader\n",
    "from model import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: #When actually training\n",
    "    train_path_labels=Path_labels(pd.read_csv(r\"C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels_train.csv\", index_col=0))\n",
    "    test_path_labels=Path_labels(pd.read_csv(r\"C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels_test.csv\", index_col=0))\n",
    "else: #when verifying the codes\n",
    "    train_path_labels=Path_labels(pd.read_csv(r\"C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels_train.csv\", index_col=0)[:10])\n",
    "    test_path_labels=Path_labels(pd.read_csv(r\"C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\sorted_labels_test.csv\", index_col=0)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=OpenFace_DataLoader(n=10, #number of frames per video\n",
    "                                path_labels=train_path_labels, #path information to load the csv files (consider path like a pointer)\n",
    "                                batch_size=500, #note: batch_size must be divided by n (e.g., 500/10=50 => fine)\n",
    "                                feature_set=None, #None means auto mode to decide features to be used for X\n",
    "                                y_col=['Engagement'], #In this study, only Engagement labels are used\n",
    "                                seed=0) #for reproductivity\n",
    "\n",
    "testloader=OpenFace_DataLoader(n=10, #number of frames per video\n",
    "                                path_labels=test_path_labels, #path information to load the csv files (consider path like a pointer)\n",
    "                                batch_size=500, #note: batch_size must be divided by n (e.g., 500/10=50 => fine)\n",
    "                                feature_set=None, #None means auto mode to decide features to be used for X\n",
    "                                y_col=['Engagement'], #In this study, only Engagement labels are used\n",
    "                                seed=0) #for reproductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54820"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.len_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader.to('cuda')\n",
    "testloader.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del MLP\n",
    "from model import MLP\n",
    "import torch\n",
    "from os.path import join as ospj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "D_in=len(OpenFace_DataLoader.columns)-len([\n",
    "    'frame', 'face_id', 'timestamp', \n",
    "    'confidence', 'success', 'Boredom', \n",
    "    'Engagement', 'Confusion', 'Frustration'])\n",
    "print(D_in)\n",
    "model=MLP([D_in, 256, 64, 16, 4], \n",
    "            n_classes=2,\n",
    "            loss_function='CrossEntropyLoss', loss_function_params=dict(),\n",
    "            optimizer='Adam', optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n",
    "            af='ReLU', af_params=dict(),\n",
    "            af_fin='Sigmoid', af_fin_params=dict(),\n",
    "            attach_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.9547610361182051\t0.950667440510737\n",
      "1\t0.9547610361182051\t0.950667440510737\n",
      "2\t0.9547610361182051\t0.950667440510737\n",
      "3\t0.9547610361182051\t0.950667440510737\n",
      "4\t0.9547610361182051\t0.950667440510737\n",
      "5\t0.9547610361182051\t0.950667440510737\n",
      "6\t0.9547610361182051\t0.950667440510737\n",
      "7\t0.9547610361182051\t0.950667440510737\n",
      "8\t0.9547610361182051\t0.950667440510737\n",
      "9\t0.9547610361182051\t0.950667440510737\n",
      "10\t0.9547610361182051\t0.950667440510737\n",
      "11\t0.9547610361182051\t0.950667440510737\n",
      "12\t0.9547610361182051\t0.950667440510737\n",
      "13\t0.9547610361182051\t0.950667440510737\n",
      "14\t0.9547610361182051\t0.950667440510737\n",
      "15\t0.9547610361182051\t0.950667440510737\n",
      "16\t0.9547610361182051\t0.950667440510737\n",
      "17\t0.9547610361182051\t0.950667440510737\n",
      "18\t0.9547610361182051\t0.950667440510737\n",
      "19\t0.9547610361182051\t0.950667440510737\n",
      "20\t0.9547610361182051\t0.950667440510737\n",
      "21\t0.9547610361182051\t0.950667440510737\n",
      "22\t0.9547610361182051\t0.950667440510737\n",
      "23\t0.9547610361182051\t0.950667440510737\n",
      "24\t0.9547610361182051\t0.950667440510737\n",
      "25\t0.9547610361182051\t0.950667440510737\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     labels_te\u001b[39m+\u001b[39m\u001b[39m=\u001b[39my\u001b[39m.\u001b[39mravel()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     model\u001b[39m.\u001b[39;49mtrain(trainloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, attach_label_onehot\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, attach_label_binarize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     13\u001b[0m     pred_tr\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtest(trainloader, attach_label_onehot\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, attach_label_binarize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#validation\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     pred_te\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtest(testloader, attach_label_onehot\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, attach_label_binarize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#test\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\Desktop\\Package\\Smart-Education\\EngaementModel\\model.py:75\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, dataLoader, epochs, attach_label_onehot, attach_label_binarize)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39melif\u001b[39;00m attach_label_binarize:\n\u001b[0;32m     74\u001b[0m     label\u001b[39m=\u001b[39m(label\u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m)\u001b[39m.\u001b[39mint()\u001b[39m.\u001b[39mlong()\n\u001b[1;32m---> 75\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[0;32m     76\u001b[0m output\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m(x)\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes\u001b[39m>\u001b[39m\u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:279\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    277\u001b[0m     p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m foreach \u001b[39mor\u001b[39;00m p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mis_sparse):\n\u001b[1;32m--> 279\u001b[0m     p\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mzero_()\n\u001b[0;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     per_device_and_dtype_grads[p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdevice][p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdtype]\u001b[39m.\u001b[39mappend(p\u001b[39m.\u001b[39mgrad)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "torch.manual_seed(0)\n",
    "\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "for _, y in trainloader:\n",
    "    labels_tr+=y.ravel().detach().cpu()\n",
    "for _, y in testloader:\n",
    "    labels_te+=y.ravel().detach().cpu()\n",
    "for i in range(50):\n",
    "    model.train(trainloader, epochs=100, attach_label_onehot=False, attach_label_binarize=True)\n",
    "    pred_tr=model.test(trainloader, attach_label_onehot=False, attach_label_binarize=True) #validation\n",
    "    pred_te=model.test(testloader, attach_label_onehot=False, attach_label_binarize=True) #test\n",
    "    acc_tr=accuracy_score(np.array(labels_tr)>=2.0, pred_tr.detach().argmax(dim=1).cpu().numpy())\n",
    "    acc_te=accuracy_score(np.array(labels_te)>=2.0, pred_te.detach().argmax(dim=1).cpu().numpy())\n",
    "    print(i, acc_tr, acc_te, sep='\\t')\n",
    "    if acc_tr>=0.9 or acc_te>=0.9:\n",
    "        if SAVE_MODELS:\n",
    "            torch.save(model, ospj(path, f'MLP_clf_CE_ep{(i+1)*100}'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification - Binary Cross Entropy Loss Model (trained with 4-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "D_in=len(OpenFace_DataLoader.columns)-len([\n",
    "    'frame', 'face_id', 'timestamp', \n",
    "    'confidence', 'success', 'Boredom', \n",
    "    'Engagement', 'Confusion', 'Frustration'])\n",
    "print(D_in)\n",
    "model=MLP([D_in, 256, 64, 16, 4], \n",
    "            n_classes=4,\n",
    "            loss_function='BCELoss', loss_function_params=dict(),\n",
    "            optimizer='Adam', optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n",
    "            af='ReLU', af_params=dict(),\n",
    "            af_fin='Sigmoid', af_fin_params=dict(),\n",
    "            attach_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score\n",
      "0\t0.7126960963152135\t0.48479396401625074\t0.9547610361182051\t0.950667440510737\n",
      "Accuracy Score\n",
      "1\t0.7498358263407515\t0.4759721416134649\t0.9549069682597592\t0.9456181079512478\n",
      "Accuracy Score\n",
      "2\t0.7734038672017511\t0.4690075449796866\t0.956238599051441\t0.9386535113174695\n",
      "Accuracy Score\n",
      "3\t0.7687887632251004\t0.47701683110853166\t0.9597044874133528\t0.9342426001160766\n",
      "Accuracy Score\n",
      "4\t0.8122400583728566\t0.47115496227510156\t0.9629879605983218\t0.9239698200812536\n",
      "Accuracy Score\n",
      "5\t0.8315578256110908\t0.46674405107370864\t0.9660525355709595\t0.9291932675565874\n",
      "Accuracy Score\n",
      "6\t0.8236045238963882\t0.46221706326175277\t0.9653775994162714\t0.928322692977365\n",
      "Accuracy Score\n",
      "7\t0.8321597956950019\t0.4834590829947766\t0.9667821962787304\t0.924724318049913\n",
      "Accuracy Score\n",
      "8\t0.8358263407515505\t0.47661056297156124\t0.9676395476103612\t0.9209518282066164\n",
      "Accuracy Score\n",
      "9\t0.8280372126960963\t0.4825304701102728\t0.9673841663626414\t0.9264654672083575\n",
      "Accuracy Score\n",
      "10\t0.8628420284567676\t0.46767266395821244\t0.9712148850784386\t0.9219965177016831\n",
      "Accuracy Score\n",
      "11\t0.8502553812477198\t0.479570516540917\t0.9698832542867567\t0.928322692977365\n",
      "Accuracy Score\n",
      "12\t0.8473914629697191\t0.4775972141613465\t0.96917183509668\t0.9251886244921649\n",
      "Accuracy Score\n",
      "13\t0.8560744253921926\t0.4759141033081834\t0.9698285297336738\t0.9236215902495647\n",
      "Accuracy Score\n",
      "14\t0.8674753739511127\t0.4680789320951828\t0.9717621306092666\t0.922460824143935\n",
      "Accuracy Score\n",
      "15\t0.8708318132068588\t0.4723737666860128\t0.9717621306092666\t0.9221706326175275\n",
      "Accuracy Score\n",
      "16\t0.8730025538124772\t0.4704004643064423\t0.9720357533746807\t0.9225769007544979\n",
      "Accuracy Score\n",
      "17\t0.8566946369937979\t0.47312826465467206\t0.9717986136446553\t0.9229831688914684\n",
      "Accuracy Score\n",
      "18\t0.8803356439255746\t0.4778874056877539\t0.9743706676395476\t0.924260011607661\n",
      "Accuracy Score\n",
      "19\t0.869974461875228\t0.4694718514219385\t0.9729478292593944\t0.9197330237957052\n",
      "Accuracy Score\n",
      "20\t0.8767967894928858\t0.4749854904236796\t0.971652681503101\t0.9226349390597794\n",
      "Accuracy Score\n",
      "21\t0.8611455673112003\t0.4782936738247243\t0.9718898212331266\t0.918630295995357\n",
      "Accuracy Score\n",
      "22\t0.8659795695001824\t0.4666279744631457\t0.9717074060561839\t0.9209518282066164\n",
      "Accuracy Score\n",
      "23\t0.8670375775264502\t0.4704004643064423\t0.9716344399854068\t0.920661636680209\n",
      "Accuracy Score\n",
      "24\t0.8789675300985041\t0.46964596633778294\t0.9741700109449106\t0.9240278583865351\n",
      "Accuracy Score\n",
      "25\t0.8902407880335644\t0.47661056297156124\t0.9757570229843123\t0.9193847939640163\n",
      "Accuracy Score\n",
      "26\t0.8832542867566582\t0.4721996517701683\t0.9747902225465158\t0.9190946024376089\n",
      "Accuracy Score\n",
      "27\t0.8793323604523896\t0.46912362159024956\t0.9739511127325794\t0.9149738827626234\n",
      "Accuracy Score\n",
      "28\t0.8653228748631886\t0.46598955310504936\t0.9728383801532288\t0.9167730702263494\n",
      "Accuracy Score\n",
      "29\t0.8868478657424298\t0.47260591990713874\t0.975337468077344\t0.9205455600696459\n",
      "Accuracy Score\n",
      "30\t0.8924115286391828\t0.47278003482298314\t0.9756840569135352\t0.9160185722576901\n",
      "Accuracy Score\n",
      "31\t0.8754469171835096\t0.46302959953569356\t0.9730207953301715\t0.918282066163668\n",
      "Accuracy Score\n",
      "32\t0.8894199197373222\t0.467498549042368\t0.9755746078073696\t0.916366802089379\n",
      "Accuracy Score\n",
      "33\t0.8794782925939438\t0.4694718514219385\t0.9743159430864647\t0.9153801508995937\n",
      "Accuracy Score\n",
      "34\t0.8856256840569136\t0.4643064422518862\t0.9746807734403502\t0.9177597214161346\n",
      "Accuracy Score\n",
      "35\t0.8518423932871215\t0.46506094022054556\t0.9706493980299161\t0.9172373766686013\n",
      "Accuracy Score\n",
      "36\t0.863133892739876\t0.47254788160185723\t0.9729843122947829\t0.9190365641323274\n",
      "Accuracy Score\n",
      "37\t0.8802626778547975\t0.46500290191526406\t0.9742794600510762\t0.9173534532791643\n",
      "Accuracy Score\n",
      "38\t0.8738599051441079\t0.45861868833430064\t0.9737504560379423\t0.9163087637840975\n",
      "Accuracy Score\n",
      "39\t0.8916636264137177\t0.4665699361578642\t0.975665815395841\t0.9180499129425421\n",
      "Accuracy Score\n",
      "40\t0.8690623859905144\t0.471561230412072\t0.9723641006931777\t0.9188624492164829\n",
      "Accuracy Score\n",
      "41\t0.871853338197738\t0.4570516540917005\t0.9740788033564393\t0.9179338363319791\n",
      "Accuracy Score\n",
      "42\t0.8834002188982123\t0.47086477074869415\t0.9737869390733309\t0.9211259431224609\n",
      "Accuracy Score\n",
      "43\t0.8821962787303904\t0.46680208937899015\t0.9734221087194455\t0.9196169471851422\n",
      "Accuracy Score\n",
      "44\t0.8958226924480117\t0.46500290191526406\t0.9756110908427581\t0.9210098665118979\n",
      "Accuracy Score\n",
      "45\t0.8590113097409704\t0.465467208357516\t0.9709412623130245\t0.9177597214161346\n",
      "Accuracy Score\n",
      "46\t0.8818132068588107\t0.46395821242019736\t0.9737504560379423\t0.9186883343006385\n",
      "Accuracy Score\n",
      "47\t0.8692995257205399\t0.46871735345327914\t0.9721087194454578\t0.9244341265235055\n",
      "Accuracy Score\n",
      "48\t0.8834549434512952\t0.47614625652930936\t0.9741882524626049\t0.9171793383633198\n",
      "Accuracy Score\n",
      "49\t0.8894016782196279\t0.4702263493905978\t0.9748814301349872\t0.9227510156703425\n"
     ]
    }
   ],
   "source": [
    "# path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "# torch.manual_seed(0)\n",
    "# for i in range(50):\n",
    "#     model.train(trainloader, epochs=100, attach_label_onehot=True, attach_label_binarize=False)\n",
    "#     pred=model.test(trainloader, attach_label_onehot=True, attach_label_binarize=False)\n",
    "#     labels=[]\n",
    "#     for _, y in trainloader:\n",
    "#         labels+=y.ravel().detach().cpu()\n",
    "#     from sklearn.metrics import accuracy_score\n",
    "#     # print(np.array(labels)[:5])\n",
    "#     # print(np.round(pred.detach().cpu().argmax(dim=1).numpy())[:5])\n",
    "#     acc=np.sum(np.array(labels)==np.round(pred.detach().cpu().argmax(dim=1).reshape(-1).numpy()))/len(labels)\n",
    "#     acc_b=accuracy_score(np.array(labels)>=2.0, pred.detach().cpu().argmax(dim=1).reshape(-1).numpy()>=2.0)\n",
    "#     print(i, acc, acc_b, sep='\\t')\n",
    "    # [[0, 1, 2],\n",
    "    #  [1, 2, 3]]\n",
    "    # argmax(dim=0) -> [1, 1, 1]\n",
    "    # argmax(dim=1) -> [2, 2]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "torch.manual_seed(0)\n",
    "\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "for _, y in trainloader:\n",
    "    labels_tr+=y.ravel().detach().cpu()\n",
    "for _, y in testloader:\n",
    "    labels_te+=y.ravel().detach().cpu()\n",
    "for i in range(50):\n",
    "    model.train(trainloader, epochs=100, attach_label_onehot=True, attach_label_binarize=False)\n",
    "    pred_tr=model.test(trainloader, attach_label_onehot=True, attach_label_binarize=False) #validation\n",
    "    pred_te=model.test(testloader, attach_label_onehot=True, attach_label_binarize=False) #test\n",
    "    acc_tr=np.sum(np.array(labels_tr)==np.round(pred_tr.detach().cpu().argmax(dim=1).reshape(-1).numpy()))/len(labels_tr)\n",
    "    acc_te=np.sum(np.array(labels_te)==np.round(pred_te.detach().cpu().argmax(dim=1).reshape(-1).numpy()))/len(labels_te)\n",
    "    acc_tr_b=accuracy_score(np.array(labels_tr)>=2.0, pred_tr.detach().cpu().argmax(dim=1).reshape(-1).numpy()>=2.0)\n",
    "    acc_te_b=accuracy_score(np.array(labels_te)>=2.0, pred_te.detach().cpu().argmax(dim=1).reshape(-1).numpy()>=2.0)\n",
    "    print('Accuracy Score')\n",
    "    print(i, acc_tr, acc_te, acc_tr_b, acc_te_b, sep='\\t')\n",
    "    if acc_tr_b>=0.9 or acc_te_b>=0.9:\n",
    "        if SAVE_MODELS:\n",
    "            torch.save(model, ospj(path, f'MLP_clf_BCE_ep{(i+1)*100}'))\n",
    "    \n",
    "\n",
    "# 44\t0.8958226924480117\t0.46500290191526406\t0.9756110908427581\t0.9210098665118979 => 4500 epochs\n",
    "        0.8958226924480117\t0.46500290191526406\t0.9756110908427581\t0.9210098665118979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 -level classification XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "D_in=len(OpenFace_DataLoader.columns)-len([\n",
    "    'frame', 'face_id', 'timestamp', \n",
    "    'confidence', 'success', 'Boredom', \n",
    "    'Engagement', 'Confusion', 'Frustration'])\n",
    "print(D_in)\n",
    "model=XGBClassifier([D_in, 256, 64, 16, 4, 1], \n",
    "            n_classes=1,\n",
    "            loss_function='MSELoss', loss_function_params=dict(),\n",
    "            optimizer='Adam', optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n",
    "            af='ReLU', af_params=dict(),\n",
    "            af_fin='Tanh', af_fin_params=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     labels_te\u001b[39m+\u001b[39m\u001b[39m=\u001b[39my\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     model\u001b[39m.\u001b[39;49mtrain(trainloader, epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m     11\u001b[0m     pred_tr\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtest(trainloader)\n\u001b[0;32m     12\u001b[0m     pred_te\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtest(testloader)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "from sklearn.metrics import accuracy_score\n",
    "torch.manual_seed(0)\n",
    "labels_tr, labels_te=[], []\n",
    "for _, y in trainloader:\n",
    "    labels_tr+=y.detach().cpu()\n",
    "for _, y in testloader:\n",
    "    labels_te+=y.detach().cpu()\n",
    "for i in range(50):\n",
    "    model.train(trainloader, epochs=100)\n",
    "    pred_tr=model.test(trainloader)\n",
    "    pred_te=model.test(testloader)\n",
    "    def map_(values, clip_low, clip_high):\n",
    "        result=[]\n",
    "        for value in values:\n",
    "            value=value[0] #flattening\n",
    "            val=clip_low if value<clip_low else clip_high if value>clip_high else value\n",
    "            result.append(val)\n",
    "        return np.round(np.array(result))\n",
    "    # print(np.array(labels)[:5])\n",
    "    # print(pred[:5])\n",
    "    # print(map_(pred.detach().cpu().numpy(), 0.0, 3.0)[:5])\n",
    "    acc_tr=np.sum(np.array(labels_tr)==map_(pred_tr.detach().cpu().numpy(), 0.0, 3.0))/len(labels_tr)\n",
    "    acc_te=np.sum(np.array(labels_te)==map_(pred_te.detach().cpu().numpy(), 0.0, 3.0))/len(labels_te)\n",
    "    acc_tr_b=accuracy_score(np.array(labels_tr)>=2.0, map_(pred_tr.detach().cpu().numpy(), 0.0, 3.0)>=2.0)\n",
    "    acc_te_b=accuracy_score(np.array(labels_te)>=2.0, map_(pred_te.detach().cpu().numpy(), 0.0, 3.0)>=2.0)\n",
    "    print(i, acc_tr, acc_te, acc_tr_b, acc_te_b, sep='\\t')\n",
    "    if acc_tr_b>=0.9 or acc_te_b>=0.9:\n",
    "        if SAVE_MODELS:\n",
    "            torch.save(model, ospj(path, f'MLP_reg_ep{(i+1)*100}'))\n",
    "    # 33\t0.7965705946734768\t0.45397562391178176\t0.9701386355344764\t0.918398142774231 => 3400 epochs\n",
    "\n",
    "\n",
    "# 44\t0.8958226924480117\t0.46500290191526406\t0.9756110908427581\t0.9210098665118979 => 4500 epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Regressor approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del MLP\n",
    "from model import MLPRegressor\n",
    "import torch\n",
    "from os.path import join as ospj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "D_in=len(OpenFace_DataLoader.columns)-len([\n",
    "    'frame', 'face_id', 'timestamp', \n",
    "    'confidence', 'success', 'Boredom', \n",
    "    'Engagement', 'Confusion', 'Frustration'])\n",
    "print(D_in)\n",
    "model=MLPRegressor([D_in, 256, 64, 16, 4, 1], \n",
    "            n_classes=1,\n",
    "            loss_function='MSELoss', loss_function_params=dict(),\n",
    "            optimizer='Adam', optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n",
    "            af='ReLU', af_params=dict(),\n",
    "            af_fin='Tanh', af_fin_params=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     labels_te\u001b[39m+\u001b[39m\u001b[39m=\u001b[39my\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     model\u001b[39m.\u001b[39;49mtrain(trainloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m     pred_tr\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtest(trainloader)\n\u001b[0;32m     12\u001b[0m     pred_te\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtest(testloader)\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\Desktop\\Package\\Smart-Education\\EngaementModel\\model.py:182\u001b[0m, in \u001b[0;36mMLPRegressor.train\u001b[1;34m(self, dataLoader, epochs)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m x, label \u001b[39min\u001b[39;00m dataLoader:\n\u001b[0;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 182\u001b[0m     output\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m(x)\n\u001b[0;32m    183\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, label\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_losses\u001b[39m=\u001b[39mloss \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_losses\u001b[39m==\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mvstack((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_losses, loss))\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\Desktop\\Package\\Smart-Education\\EngaementModel\\model.py:176\u001b[0m, in \u001b[0;36mMLPRegressor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    173\u001b[0m     \u001b[39m# if self.attach_softmax:\u001b[39;00m\n\u001b[0;32m    174\u001b[0m         \u001b[39m# return self.softmax(self.estimator(x))\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[39m# else:\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator(x)\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "path=r'C:\\GitHub\\Smart-Education-data\\data\\DAiSEE\\Sorted\\Saved_models'\n",
    "from sklearn.metrics import accuracy_score\n",
    "torch.manual_seed(0)\n",
    "labels_tr, labels_te=[], []\n",
    "for _, y in trainloader:\n",
    "    labels_tr+=y.detach().cpu()\n",
    "for _, y in testloader:\n",
    "    labels_te+=y.detach().cpu()\n",
    "for i in range(50):\n",
    "    model.train(trainloader, epochs=100)\n",
    "    pred_tr=model.test(trainloader)\n",
    "    pred_te=model.test(testloader)\n",
    "    def map_(values, clip_low, clip_high):\n",
    "        result=[]\n",
    "        for value in values:\n",
    "            value=value[0] #flattening\n",
    "            val=clip_low if value<clip_low else clip_high if value>clip_high else value\n",
    "            result.append(val)\n",
    "        return np.round(np.array(result))\n",
    "    # print(np.array(labels)[:5])\n",
    "    # print(pred[:5])\n",
    "    # print(map_(pred.detach().cpu().numpy(), 0.0, 3.0)[:5])\n",
    "    acc_tr=np.sum(np.array(labels_tr)==map_(pred_tr.detach().cpu().numpy(), 0.0, 3.0))/len(labels_tr)\n",
    "    acc_te=np.sum(np.array(labels_te)==map_(pred_te.detach().cpu().numpy(), 0.0, 3.0))/len(labels_te)\n",
    "    acc_tr_b=accuracy_score(np.array(labels_tr)>=2.0, map_(pred_tr.detach().cpu().numpy(), 0.0, 3.0)>=2.0)\n",
    "    acc_te_b=accuracy_score(np.array(labels_te)>=2.0, map_(pred_te.detach().cpu().numpy(), 0.0, 3.0)>=2.0)\n",
    "    print(i, acc_tr, acc_te, acc_tr_b, acc_te_b, sep='\\t')\n",
    "    if acc_tr_b>=0.9 or acc_te_b>=0.9:\n",
    "        if SAVE_MODELS:\n",
    "            torch.save(model, ospj(path, f'MLP_reg_ep{(i+1)*100}'))\n",
    "    # 33\t0.7965705946734768\t0.45397562391178176\t0.9701386355344764\t0.918398142774231 => 3400 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Regressor approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model=XGBRegressor(random_state=0, verbosity=0)\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping function that maps prediction (floating point) to integer labels(0, 1, 2, 3). Same as the MLP's one\n",
    "def map_(values, clip_low, clip_high):\n",
    "    result=[]\n",
    "    for value in values:\n",
    "        # value=value[0] #flattening #no need for XGBoost\n",
    "        val=clip_low if value<clip_low else clip_high if value>clip_high else value\n",
    "        result.append(val)\n",
    "    return np.round(np.array(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy score\n",
      "0.8448011674571324 0.5032501450957632 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "print('Acuuracy score')\n",
    "acc_tr=accuracy_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "acc_te=accuracy_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "acc_te_b=accuracy_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "print(acc_tr, acc_te, acc_tr_b, acc_te_b)\n",
    "\n",
    "# print('Precision score')\n",
    "# # pre_tr=precision_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# # pre_te=precision_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# pre_tr_b=precision_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# pre_te_b=precision_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(pre_tr_b, pre_te_b)\n",
    "\n",
    "# print('Recall score')\n",
    "# # rec_tr=recall_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# # rec_te=recall_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# rec_tr_b=recall_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# rec_te_b=recall_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(rec_tr_b, rec_te_b)\n",
    "\n",
    "# print('F1 score')\n",
    "# # f1_tr=f1_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# # f1_te=f1_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# f1_tr_b=f1_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# f1_te_b=f1_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(f1_tr_b, f1_te_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([2.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32), array([3.], dtype=float32)]\n",
      "[2.7154076, 2.487681, 2.622789, 2.7050722, 2.713153, 2.6488135, 2.7496548, 2.6400206, 2.4623835, 2.5451715, 2.5754857, 2.5243242, 2.5216355, 2.4960322, 2.2102094, 2.5973086, 2.6765635, 2.6449294, 2.7800288, 2.7599394, 2.595357, 2.6087344, 2.9121063, 2.8470542, 2.7275476, 2.6486623, 2.9637167, 2.464454, 2.5463269, 2.7175522, 2.7507975, 2.718527, 2.7091088, 2.7049937, 2.7013757, 2.753985, 2.7204309, 2.7787838, 2.7771165, 2.8111734, 2.703996, 2.7802708, 2.7557118, 2.7225163, 2.6171947, 2.666545, 2.7455964, 2.812322, 2.6902773, 2.6986082, 2.6171134, 2.4915178, 2.2969856, 2.7284527, 2.7175612, 2.6546128, 2.3216789, 2.6490912, 2.6521423, 2.7097397, 2.7655616, 2.7512655, 2.8060465, 2.771105, 2.754731, 2.7980874, 2.7664945, 2.8504837, 2.804881, 2.8055444, 2.4115338, 2.7121136, 2.6139946, 2.6164594, 2.659512, 2.7030752, 2.7157326, 2.6839244, 2.6160388, 2.7133117, 2.8802013, 2.6968675, 2.8223472, 2.821161, 2.826379, 2.777826, 2.8838155, 2.7299883, 3.103097, 2.777826, 2.8736298, 2.9238598, 2.550521, 2.8003387, 2.903362, 2.9253404, 2.9022853, 2.8360007, 2.9442046, 2.6774955]\n",
      "[3. 2. 3. 3. 3. 3. 3. 3. 2. 3. 3. 3. 3. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 2. 2. 3. 3. 3. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 2. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=100\n",
    "print(labels_tr[start:end])\n",
    "print(pred_tr[start:end])\n",
    "print(map_(pred_tr, 0.0, 3.0)[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    26490\n",
       "3.0    25850\n",
       "1.0     2140\n",
       "0.0      340\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(labels_tr).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model=XGBClassifier(random_state=0, verbosity=0)\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "print('Acuuracy score')\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr), pred_tr)\n",
    "acc_te_b=accuracy_score(np.array(labels_te), pred_te)\n",
    "print(acc_tr_b, acc_te_b)\n",
    "# print('Precision score')\n",
    "# pre_tr= precision_score(np.array(labels_tr), pred_tr)\n",
    "# pre_te= precision_score(np.array(labels_te), pred_te)\n",
    "# print(pre_tr, pre_te)\n",
    "# print('Recall score')\n",
    "# rec_tr = recall_score(np.array(labels_tr), pred_tr)\n",
    "# rec_te = recall_score(np.array(labels_te), pred_te)\n",
    "# print(rec_tr, rec_te)\n",
    "# print('F1 score')\n",
    "# f1_tr = f1_score(np.array(labels_tr), pred_tr)\n",
    "# f1_te = f1_score(np.array(labels_te), pred_te)\n",
    "# print(f1_tr, f1_te)\n",
    "\n",
    "# P = 100 # Number of positive samples\n",
    "# N = 200 # Number of negative samples\n",
    "\n",
    "# Calculate TP, FP, FN, and TN\n",
    "# TP = recall * P\n",
    "# FP = (1 - precision) * (N - P)\n",
    "# FN = TP * (1 - accuracy) / accuracy\n",
    "# TN = N - FP - FN - TP\n",
    "\n",
    "# Create the confusion matrix\n",
    "# conf_mat = confusion_matrix([0, 1], [[TN, FP], [FN, TP]])\n",
    "\n",
    "# print(conf_mat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Classifier Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model=SVC(random_state=0)\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "print('Acuuracy score')\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr), pred_tr)\n",
    "acc_te_b=accuracy_score(np.array(labels_te), pred_te)\n",
    "print(acc_tr_b, acc_te_b)\n",
    "# print('Precision score')\n",
    "# pre_tr= precision_score(np.array(labels_tr), pred_tr)\n",
    "# pre_te= precision_score(np.array(labels_te), pred_te)\n",
    "# print(pre_tr, pre_te)\n",
    "# print('Recall score')\n",
    "# rec_tr = recall_score(np.array(labels_tr), pred_tr)\n",
    "# rec_te = recall_score(np.array(labels_te), pred_te)\n",
    "# print(rec_tr, rec_te)\n",
    "# print('F1 score')\n",
    "# f1_tr = f1_score(np.array(labels_tr), pred_tr)\n",
    "# f1_te = f1_score(np.array(labels_te), pred_te)\n",
    "# print(f1_tr, f1_te)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Regressor Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ranjani\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "model=SVR()\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping function that maps prediction (floating point) to integer labels(0, 1, 2, 3). Same as the MLP's one\n",
    "def map_(values, clip_low, clip_high):\n",
    "    result=[]\n",
    "    for value in values:\n",
    "        # value=value[0] #flattening #no need for XGBoost\n",
    "        val=clip_low if value<clip_low else clip_high if value>clip_high else value\n",
    "        result.append(val)\n",
    "    return np.round(np.array(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score\n",
      "0.039000364830353886 0.047011027278003485 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "print('Accuracy score')\n",
    "acc_tr=accuracy_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "acc_te=accuracy_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "acc_te_b=accuracy_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "\n",
    "print(acc_tr, acc_te, acc_tr_b, acc_te_b)\n",
    "\n",
    "# print('Precision score')\n",
    "# pre_tr=precision_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# pre_te=precision_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# pre_tr_b=precision_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# pre_te_b=precision_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(pre_tr, pre_te, pre_tr_b, pre_te_b)\n",
    "\n",
    "# print('Recall score')\n",
    "# rec_tr=recall_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# rec_te=recall_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# rec_tr_b=recall_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# rec_te_b=recall_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(rec_tr, rec_te, rec_tr_b, rec_te_b)\n",
    "\n",
    "# print('F1 score')\n",
    "# f1_tr=f1_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# f1_te=f1_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# f1_tr_b=f1_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# f1_te_b=f1_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(f1_tr, f1_te, f1_tr_b, f1_te_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier()\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "\n",
    "print('Acuuracy score')\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr), pred_tr)\n",
    "acc_te_b=accuracy_score(np.array(labels_te), pred_te)\n",
    "print(acc_tr_b, acc_te_b)\n",
    "# print('Precision score')\n",
    "# pre_tr= precision_score(np.array(labels_tr), pred_tr)\n",
    "# pre_te= precision_score(np.array(labels_te), pred_te)\n",
    "# print(pre_tr, pre_te)\n",
    "# print('Recall score')\n",
    "# rec_tr = recall_score(np.array(labels_tr), pred_tr)\n",
    "# rec_te = recall_score(np.array(labels_te), pred_te)\n",
    "# print(rec_tr, rec_te)\n",
    "# print('F1 score')\n",
    "# f1_tr = f1_score(np.array(labels_tr), pred_tr)\n",
    "# f1_te = f1_score(np.array(labels_te), pred_te)\n",
    "# print(f1_tr, f1_te)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranjani\\AppData\\Local\\Temp\\ipykernel_7108\\4286751618.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(np.array(data), np.array(label))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping function that maps prediction (floating point) to integer labels(0, 1, 2, 3). Same as the MLP's one\n",
    "def map_(values, clip_low, clip_high):\n",
    "    result=[]\n",
    "    for value in values:\n",
    "        # value=value[0] #flattening #no need for XGBoost\n",
    "        val=clip_low if value<clip_low else clip_high if value>clip_high else value\n",
    "        result.append(val)\n",
    "    return np.round(np.array(result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score\n",
      "0.006202116016052536 0.04596633778293674 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "print('Accuracy score')\n",
    "acc_tr=accuracy_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "acc_te=accuracy_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "acc_te_b=accuracy_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "\n",
    "print(acc_tr, acc_te, acc_tr_b, acc_te_b)\n",
    "\n",
    "# print('Precision score')\n",
    "# pre_tr=precision_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# pre_te=precision_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# pre_tr_b=precision_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# pre_te_b=precision_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(pre_tr, pre_te, pre_tr_b, pre_te_b)\n",
    "\n",
    "# print('Recall score')\n",
    "# rec_tr=recall_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# rec_te=recall_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# rec_tr_b=recall_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# rec_te_b=recall_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(rec_tr, rec_te, rec_tr_b, rec_te_b)\n",
    "\n",
    "# print('F1 score')\n",
    "# f1_tr=f1_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# f1_te=f1_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# f1_tr_b=f1_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# f1_te_b=f1_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(f1_tr, f1_te, f1_tr_b, f1_te_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model=KNeighborsClassifier(n_neighbors=5)\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "print('Acuuracy score')\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr), pred_tr)\n",
    "acc_te_b=accuracy_score(np.array(labels_te), pred_te)\n",
    "print(acc_tr_b, acc_te_b)\n",
    "print('Precision score')\n",
    "pre_tr= precision_score(np.array(labels_tr), pred_tr)\n",
    "pre_te= precision_score(np.array(labels_te), pred_te)\n",
    "print(pre_tr, pre_te)\n",
    "print('Recall score')\n",
    "rec_tr = recall_score(np.array(labels_tr), pred_tr)\n",
    "rec_te = recall_score(np.array(labels_te), pred_te)\n",
    "print(rec_tr, rec_te)\n",
    "print('F1 score')\n",
    "f1_tr = f1_score(np.array(labels_tr), pred_tr)\n",
    "f1_te = f1_score(np.array(labels_te), pred_te)\n",
    "print(f1_tr, f1_te)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model=KNeighborsRegressor(n_neighbors=5)\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "data=[]\n",
    "label=[]\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()>=2.0\n",
    "    data+=list(X)\n",
    "    label+=list(Y)\n",
    "model.fit(np.array(data), np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping function that maps prediction (floating point) to integer labels(0, 1, 2, 3). Same as the MLP's one\n",
    "def map_(values, clip_low, clip_high):\n",
    "    result=[]\n",
    "    for value in values:\n",
    "        # value=value[0] #flattening #no need for XGBoost\n",
    "        val=clip_low if value<clip_low else clip_high if value>clip_high else value\n",
    "        result.append(val)\n",
    "    return np.round(np.array(result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsRegressor Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score\n",
      "0.01661802261948194 0.045908299477655255 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "pred_tr=[]\n",
    "pred_te=[]\n",
    "labels_tr=[]\n",
    "labels_te=[]\n",
    "trainloader.to('cpu')\n",
    "testloader.to('cpu')\n",
    "for x, y in trainloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_tr+=list(model.predict(X))\n",
    "    labels_tr+=list(Y)\n",
    "for x, y in testloader:\n",
    "    X=x.numpy()\n",
    "    Y=y.float().numpy()\n",
    "    pred_te+=list(model.predict(X))\n",
    "    labels_te+=list(Y)\n",
    "\n",
    "print('Accuracy score')\n",
    "acc_tr=accuracy_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "acc_te=accuracy_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "acc_tr_b=accuracy_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "acc_te_b=accuracy_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "\n",
    "print(acc_tr, acc_te, acc_tr_b, acc_te_b)\n",
    "\n",
    "# print('Precision score')\n",
    "# pre_tr=precision_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# pre_te=precision_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# pre_tr_b=precision_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# pre_te_b=precision_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(pre_tr, pre_te, pre_tr_b, pre_te_b)\n",
    "\n",
    "# print('Recall score')\n",
    "# rec_tr=recall_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# rec_te=recall_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# rec_tr_b=recall_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# rec_te_b=recall_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(rec_tr, rec_te, rec_tr_b, rec_te_b)\n",
    "\n",
    "# print('F1 score')\n",
    "# f1_tr=f1_score(labels_tr, map_(pred_tr, 0.0, 3.0))\n",
    "# f1_te=f1_score(labels_te, map_(pred_te, 0.0, 3.0))\n",
    "# f1_tr_b=f1_score(np.array(labels_tr)>=2.0, map_(labels_tr, 0.0, 3.0)>=2.0)\n",
    "# f1_te_b=f1_score(np.array(labels_te)>=2.0, map_(labels_te, 0.0, 3.0)>=2.0)\n",
    "# print(f1_tr, f1_te, f1_tr_b, f1_te_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "182000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_celeba=r'C:\\GitHub\\Smart-Education-data\\data\\celeba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import join as ospj\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20599"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(ospj(path_celeba, '*'))[182000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_id_csv=r'C:\\GitHub\\Smart-Education-data\\data\\Anno\\identity_CelebA.txt'\n",
    "df_id_all=pd.read_csv(path_id_csv, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame([list(_)[0].split() for _ in df_id_all.values], columns=['f_name', 'id'])['id'].value_counts().plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above figure, if the horizontal segment of the plot is longer, the height (y value, which is integer) is more common."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm gonna drop less common ids because we need to split them into two subsets and put them in a face recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_all=pd.DataFrame([list(_)[0].split() for _ in df_id_all.values], columns=['f_name', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182000</th>\n",
       "      <td>182001.jpg</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182001</th>\n",
       "      <td>182002.jpg</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182002</th>\n",
       "      <td>182003.jpg</td>\n",
       "      <td>4072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182003</th>\n",
       "      <td>182004.jpg</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182004</th>\n",
       "      <td>182005.jpg</td>\n",
       "      <td>2658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_name    id\n",
       "182000  182001.jpg  1210\n",
       "182001  182002.jpg   465\n",
       "182002  182003.jpg  4072\n",
       "182003  182004.jpg  2810\n",
       "182004  182005.jpg  2658"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop files used for training AttGAN. (refer to AttGAN-Python/train.py)\n",
    "df_id_test=df_id_all[182000:]\n",
    "df_id_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=30 #this will determine the amount of samples in each identity subsets. Any identities having less amount of images will be dropped.\n",
    "# df_id_test.loc[]\n",
    "# df_id_test['id']\n",
    "val_cnts=df_id_test['id'].value_counts()\n",
    "idx=val_cnts.loc[(val_cnts>=n_samples)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182000    False\n",
       "182001    False\n",
       "182002    False\n",
       "182003    False\n",
       "182004    False\n",
       "          ...  \n",
       "202594     True\n",
       "202595     True\n",
       "202596    False\n",
       "202597     True\n",
       "202598    False\n",
       "Name: id, Length: 20599, dtype: bool"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id_test['id'].isin(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_test_picked=df_id_test.loc[df_id_test['id'].isin(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "samples=[]\n",
    "source_size=0.5 #source reference split\n",
    "n_src=int(source_size*n_samples)\n",
    "n_ref=n_samples-n_src\n",
    "assert n_src>0 #and n_ref>0\n",
    "src_samples=[]\n",
    "ref_samples=[]\n",
    "for id in idx:\n",
    "    _samples=df_id_test_picked.loc[df_id_test_picked['id']==id].sample(n=n_samples, random_state=seed)\n",
    "    src_sample, ref_sample=_samples[:n_src], _samples[n_src:]\n",
    "    src_samples.append(src_sample)\n",
    "    ref_samples.append(ref_sample)\n",
    "df_id_test_samples_src, df_id_test_samples_ref=pd.concat(src_samples, axis=0).sort_index(), pd.concat(ref_samples, axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9010    15\n",
       "7358    15\n",
       "5966    15\n",
       "5256    15\n",
       "5354    15\n",
       "        ..\n",
       "8786    15\n",
       "4973    15\n",
       "8912    15\n",
       "4992    15\n",
       "8717    15\n",
       "Name: id, Length: 261, dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_id_test_samples_src))\n",
    "df_id_test_samples_src['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7760    15\n",
       "8786    15\n",
       "8496    15\n",
       "7883    15\n",
       "9194    15\n",
       "        ..\n",
       "5987    15\n",
       "6454    15\n",
       "4996    15\n",
       "5159    15\n",
       "5585    15\n",
       "Name: id, Length: 261, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_id_test_samples_ref))\n",
    "df_id_test_samples_ref['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled'\n",
    "# df_id_test_samples_src.to_csv(ospj(dir, f'id_test_{n_src}_source.csv'))\n",
    "# df_id_test_samples_ref.to_csv(ospj(dir, f'id_test_{n_ref}_reference.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mergeing df_id_XXX with other headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join as ospj\n",
    "n_src, n_ref=1, 1\n",
    "dir_csv=r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled'\n",
    "df_id_test_samples_src=pd.read_csv(ospj(dir_csv, f'id_test_{n_src}_source.csv'), index_col=0)\n",
    "df_id_test_samples_ref=pd.read_csv(ospj(dir_csv, f'id_test_{n_ref}_reference.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_anno=r'C:\\GitHub\\Smart-Education-data\\data\\Anno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_name</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202594</th>\n",
       "      <td>202595.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202595</th>\n",
       "      <td>202596.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202596</th>\n",
       "      <td>202597.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202597</th>\n",
       "      <td>202598.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202598</th>\n",
       "      <td>202599.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202599 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_name 5_o_Clock_Shadow Arched_Eyebrows Attractive  \\\n",
       "0       000001.jpg               -1               1          1   \n",
       "1       000002.jpg               -1              -1         -1   \n",
       "2       000003.jpg               -1              -1         -1   \n",
       "3       000004.jpg               -1              -1          1   \n",
       "4       000005.jpg               -1               1          1   \n",
       "...            ...              ...             ...        ...   \n",
       "202594  202595.jpg               -1              -1          1   \n",
       "202595  202596.jpg               -1              -1         -1   \n",
       "202596  202597.jpg               -1              -1         -1   \n",
       "202597  202598.jpg               -1               1          1   \n",
       "202598  202599.jpg               -1               1          1   \n",
       "\n",
       "       Bags_Under_Eyes Bald Bangs Big_Lips Big_Nose Black_Hair  ... Sideburns  \\\n",
       "0                   -1   -1    -1       -1       -1         -1  ...        -1   \n",
       "1                    1   -1    -1       -1        1         -1  ...        -1   \n",
       "2                   -1   -1    -1        1       -1         -1  ...        -1   \n",
       "3                   -1   -1    -1       -1       -1         -1  ...        -1   \n",
       "4                   -1   -1    -1        1       -1         -1  ...        -1   \n",
       "...                ...  ...   ...      ...      ...        ...  ...       ...   \n",
       "202594              -1   -1    -1        1       -1         -1  ...        -1   \n",
       "202595              -1   -1     1        1       -1         -1  ...        -1   \n",
       "202596              -1   -1    -1       -1       -1          1  ...        -1   \n",
       "202597              -1   -1    -1        1       -1          1  ...        -1   \n",
       "202598              -1   -1    -1       -1       -1         -1  ...        -1   \n",
       "\n",
       "       Smiling Straight_Hair Wavy_Hair Wearing_Earrings Wearing_Hat  \\\n",
       "0            1             1        -1                1          -1   \n",
       "1            1            -1        -1               -1          -1   \n",
       "2           -1            -1         1               -1          -1   \n",
       "3           -1             1        -1                1          -1   \n",
       "4           -1            -1        -1               -1          -1   \n",
       "...        ...           ...       ...              ...         ...   \n",
       "202594      -1            -1        -1               -1          -1   \n",
       "202595       1             1        -1               -1          -1   \n",
       "202596       1            -1        -1               -1          -1   \n",
       "202597       1            -1         1                1          -1   \n",
       "202598      -1            -1         1               -1          -1   \n",
       "\n",
       "       Wearing_Lipstick Wearing_Necklace Wearing_Necktie Young  \n",
       "0                     1               -1              -1     1  \n",
       "1                    -1               -1              -1     1  \n",
       "2                    -1               -1              -1     1  \n",
       "3                     1                1              -1     1  \n",
       "4                     1               -1              -1     1  \n",
       "...                 ...              ...             ...   ...  \n",
       "202594                1               -1              -1     1  \n",
       "202595               -1               -1              -1     1  \n",
       "202596               -1               -1              -1     1  \n",
       "202597                1               -1              -1     1  \n",
       "202598                1               -1              -1     1  \n",
       "\n",
       "[202599 rows x 41 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr=pd.read_csv(ospj(dir_anno, 'list_attr_celeba.txt'), header=None)\n",
    "cols=df_attr.iloc[1, 0].split()\n",
    "_attrs=[_.split() for _ in df_attr.iloc[2:, 0]]\n",
    "# list_attrs=[cols]+_attrs\n",
    "df_attr=pd.DataFrame(_attrs, columns=['f_name']+cols)\n",
    "df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_src=df_attr.merge(df_id_test_samples_src)\n",
    "dir_celeba=r'C:\\GitHub\\Smart-Education-data\\data\\celeba'\n",
    "df_meta_src['path']=dir_celeba+'/'+df_meta_src['f_name']\n",
    "# df_meta_src[['f_name', 'path']]\n",
    "\n",
    "df_meta_ref=df_attr.merge(df_id_test_samples_ref)\n",
    "dir_celeba=r'C:\\GitHub\\Smart-Education-data\\data\\celeba'\n",
    "df_meta_ref['path']=dir_celeba+'/'+df_meta_ref['f_name']\n",
    "# df_meta_ref[['f_name', 'path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_meta=r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled'\n",
    "# df_meta_src.to_csv(ospj(dir_meta, f'meta_s{n_src}_src.csv'))\n",
    "# df_meta_ref.to_csv(ospj(dir_meta, f'meta_s{n_ref}_ref.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copying files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from os import mkdir\n",
    "from os.path import exists as osex\n",
    "from os.path import join as ospj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_src, n_ref=15, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_meta=r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled'\n",
    "df_meta_src=pd.read_csv(ospj(dir_meta, f'meta_s{n_src}_src.csv'))\n",
    "df_meta_ref=pd.read_csv(ospj(dir_meta, f'meta_s{n_ref}_ref.csv'))\n",
    "\n",
    "dir_source=ospj(r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled', f'src_s{n_src}')\n",
    "dir_reference=ospj(r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled', f'ref_s{n_ref}')\n",
    "\n",
    "if not osex(dir_source):\n",
    "    mkdir(dir_source)\n",
    "if not osex(dir_reference):\n",
    "    mkdir(dir_reference)\n",
    "for source_path in df_meta_src['path']:\n",
    "    f_name=source_path.replace('\\\\', '/').split('/')[-1]\n",
    "    # shutil.copy2(source_path, ospj(dir_source, f_name))\n",
    "for reference_path in df_meta_ref['path']:\n",
    "    f_name=reference_path.replace('\\\\', '/').split('/')[-1]\n",
    "    # shutil.copy2(reference_path, ospj(dir_reference, f_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing attr.txt from meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join as ospj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_src, n_ref=15, 15\n",
    "list_attr=['Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Bushy_Eyebrows', 'Eyeglasses', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'No_Beard', 'Pale_Skin', 'Young']\n",
    "df_meta_src=pd.read_csv(ospj(r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled', f'meta_s{n_src}_src.csv'), index_col=0)\n",
    "data=[' '.join(line)+'\\n' for line in df_meta_src.iloc[:, :-2].loc[:, ['f_name']+list_attr].astype(str).values]\n",
    "# cols=[' '.join(df_meta_src.iloc[:, 1:-2].columns)+'\\n']\n",
    "cols=[' '.join(list_attr)+'\\n']\n",
    "length=str(len(data))\n",
    "list_text=[length+'\\n']+cols+data\n",
    "dir_to_save_list_attr=r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled'\n",
    "with open(ospj(dir_to_save_list_attr, f'list_attr_s{n_src}_src.txt'), 'w') as f:\n",
    "    f.writelines(list_text)\n",
    "\n",
    "df_meta_ref=pd.read_csv(ospj(r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled', f'meta_s{n_ref}_ref.csv'), index_col=0)\n",
    "data=[' '.join(line)+'\\n' for line in df_meta_ref.iloc[:, :-2].loc[:, ['f_name']+list_attr].astype(str).values]\n",
    "# cols=[' '.join(df_meta_ref.iloc[:, 1:-2].columns)+'\\n']\n",
    "cols=[' '.join(list_attr)+'\\n']\n",
    "length=str(len(data))\n",
    "list_text=[length+'\\n']+cols+data\n",
    "dir_to_save_list_attr=r'C:\\GitHub\\Smart-Education-data\\data\\celeba_sampled'\n",
    "with open(ospj(dir_to_save_list_attr, f'list_attr_s{n_ref}_ref.txt'), 'w') as f:\n",
    "    f.writelines(list_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40fc240bea52273cd1a1858a71b7744abb2d3b41121723fab477901189220d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
